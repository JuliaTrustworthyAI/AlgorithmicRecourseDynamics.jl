{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module Models.\n",
      "WARNING: replacing module Experiments.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"output/boston_housing_ensemble\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../src/load.jl\")\n",
    "using AlgorithmicRecourse, MLDatasets, Flux\n",
    "using Plots, PlotThemes\n",
    "theme(:juno)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)\n",
    "output_folder = \"output/boston_housing_ensemble\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, Statistics\n",
    "X = BostonHousing.features()\n",
    "y = BostonHousing.targets()\n",
    "y = Float64.(y .>= median(y)); # binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off we will just train a single neural network for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data and model:\n",
    "using Random\n",
    "Random.seed!(1234)\n",
    "using StatsBase\n",
    "dt = fit(ZScoreTransform, X, dims=2)\n",
    "StatsBase.transform!(dt, X)\n",
    "xs = Flux.unstack(X,2)\n",
    "data = zip(xs,y)\n",
    "nn = Models.build_model(input_dim=size(X)[1], n_hidden=100)\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves decent training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = false\n",
    "if run\n",
    "  # Train model:\n",
    "  using Flux.Optimise: update!, ADAM\n",
    "  using Statistics, StatsBase\n",
    "  opt = ADAM()\n",
    "  epochs = 100\n",
    "  avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "  accuracy(data) = sum(map(d ->round.(Flux.œÉ.(nn(d[1]))) .== d[2], data))[1]/length(data)\n",
    "\n",
    "  using Plots\n",
    "  anim = Animation()\n",
    "  avg_l = [avg_loss(data)]\n",
    "  p1 = scatter( ylim=(0,avg_l[1]), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Average loss\")\n",
    "  acc = [accuracy(data)]\n",
    "  p2 = scatter( ylim=(0.5,1), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Accuracy\")\n",
    "\n",
    "  for epoch = 1:epochs\n",
    "    for d in data\n",
    "      gs = gradient(params(nn)) do\n",
    "        l = loss(d...)\n",
    "      end\n",
    "      update!(opt, params(nn), gs)\n",
    "    end\n",
    "    avg_l = vcat(avg_l,avg_loss(data))\n",
    "    plot!(p1, [0:epoch], avg_l, color=1)\n",
    "    scatter!(p1, [0:epoch], avg_l, color=1)\n",
    "    acc = vcat(acc,accuracy(data))\n",
    "    plot!(p2, [0:epoch], acc, color=1)\n",
    "    scatter!(p2, [0:epoch], acc, color=1)\n",
    "    plt=plot(p1,p2, size=(600,300))\n",
    "    frame(anim, plt)\n",
    "  end\n",
    "\n",
    "  gif(anim, \"www/boston_housing_single_nn.gif\", fps=10);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing_single_nn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build and train a deep ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM()\n",
    "loss_type = :logitbinarycrossentropy\n",
    "run = false\n",
    "if run\n",
    "    K = 50\n",
    "    ùìú = Models.build_ensemble(K,kw=(input_dim=size(X)[1], n_hidden=100));\n",
    "    ùìú, anim = Models.forward(ùìú, data, opt, n_epochs=30, plot_every=10, loss_type=loss_type); # fit the ensemble\n",
    "    Models.save_ensemble(ùìú, root=output_folder) # save to disk\n",
    "    gif(anim, \"www/boston_housing_ensemble_loss.gif\", fps=25);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing_ensemble_loss.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a single run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ùìú = Models.load_ensemble(root=output_folder)\n",
    "# ùë¥ = Models.FittedEnsemble(ùìú,opt,loss_type);\n",
    "# using Random\n",
    "# Random.seed!(1234)\n",
    "# xÃÖ = X[:,(y.==0)'][:,rand(1:length((y.==0)'))] # select individual sample\n",
    "# xÃÖ = reshape(xÃÖ, (length(xÃÖ),1))\n",
    "# Œ≥ = 0.75\n",
    "# target=1.0\n",
    "# T = 1000\n",
    "# n = round(size(X)[2])\n",
    "# Œ¥ = 0.1\n",
    "# generator = GreedyGenerator(Œ¥,n,:logitbinarycrossentropy,nothing)\n",
    "# recourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥, T=T); # generate recourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare ensemble for use with AlgorithmicRecourse.jl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GreedyGenerator(0.1, 506, :logitbinarycrossentropy, nothing)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ùìú = Models.load_ensemble(root=output_folder)\n",
    "ùë¥ = Models.FittedEnsemble(ùìú, opt, loss_type);\n",
    "target=1.0\n",
    "T = 1000\n",
    "n = round(size(X)[2])\n",
    "Œ¥ = 0.1\n",
    "generator = GreedyGenerator(Œ¥,n,:logitbinarycrossentropy,nothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare grid of variables for experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables:\n",
    "Œº = [0.01,0.05,0.1]\n",
    "Œ≥ = [0.55,0.75,0.9]\n",
    "grid_ = Experiments.GridVariables(Œº, Œ≥)\n",
    "n_rounds = 10\n",
    "# Experiment:\n",
    "experiment = Experiments.Experiment(X,y,ùë¥,target,grid_,n_rounds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18-element Vector{Any}:\n",
       " (pct_valid = 1.0, avg_cost = 4.631414470763766, t = 1, Œº = 0.01, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 5.181698563212648, t = 2, Œº = 0.01, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 6.40156230931169, t = 1, Œº = 0.05, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 0.9615384615384616, avg_cost = 8.03865660418456, t = 2, Œº = 0.05, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 7.118286310622804, t = 1, Œº = 0.1, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 9.565563234854498, t = 2, Œº = 0.1, Œ≥ = 0.55, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 3.0133038346638723, t = 1, Œº = 0.01, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 5.253570214625479, t = 2, Œº = 0.01, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 6.355312738174261, t = 1, Œº = 0.05, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 8.717224328879006, t = 2, Œº = 0.05, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 10.794906206169653, t = 1, Œº = 0.1, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 12.819906395914133, t = 2, Œº = 0.1, Œ≥ = 0.75, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 2.3958297101421886, t = 1, Œº = 0.01, Œ≥ = 0.9, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 6.340346993658945, t = 2, Œº = 0.01, Œ≥ = 0.9, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 7.23602100605022, t = 1, Œº = 0.05, Œ≥ = 0.9, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 9.40638081304388, t = 2, Œº = 0.05, Œ≥ = 0.9, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 8.41724420460759, t = 1, Œº = 0.1, Œ≥ = 0.9, k = 1)\n",
       " (pct_valid = 1.0, avg_cost = 11.119352499134115, t = 2, Œº = 0.1, Œ≥ = 0.9, k = 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outcome = Experiments.run_experiment(experiment, generator, 5, T=T)\n",
    "using DataFrames, CSV\n",
    "CSV.write(\"output/boston_housing_outcome_greedy.csv\", DataFrame(outcome))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

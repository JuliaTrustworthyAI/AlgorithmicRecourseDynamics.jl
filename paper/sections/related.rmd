# Background {#related}

In this section we provide a review of the relevant literature. First, Subsection \@ref(related-recourse) discusses the existing research within the domain of Counterfactual Explanations and Algorithmic Recourse. Then, Subsection \@ref(related-shifts) presents some of the previous work on the measurement of dataset and model shifts.

## Algorithmic Recourse {#related-recourse}

A framework for Counterfactual Explanations was first proposed in 2017 by Wachter et al. @wachter2017counterfactual and has served as the baseline for most methodologies that have been proposed since then. Let $M: \mathcal{X} \mapsto \mathcal{Y}$ denote some pre-trained model that maps from inputs $X \in \mathcal{X}$ to outputs $Y \in \mathcal{Y}$. Then we are interested in minimizing the cost^[Equivalently, others have referred to this quantity as *complexity* or simply *distance*.] $C=\text{cost}(x^\prime)$ incurred by individual $x$ when moving to a counterfactual state $x^\prime$ such that the predicted outcome $M(x^\prime)$ corresponds to some target outcome $y^*$:

\begin{equation}
\min_{x^\prime \in \mathcal{X}} \text{cost}(x^\prime) \ \ \ \mbox{s. t.} \ \ \ M(x^\prime) = y^* (\#eq:obj)
\end{equation}

For implementation purposes, \@ref(eq:obj) is typically approximated through regularization:

\begin{equation}
x^\prime = \arg \min_{x^\prime}  \text{yloss}(M(x^\prime),y^*) + \lambda \text{cost}(x^\prime) (\#eq:solution)
\end{equation}

In the baseline work [@wachter2017counterfactual], the cost function is proxied by some distance metric based on the simple intuition that perturbations of $x$ are costly to the individual. For models that are differentiable and produce smooth predictions, \@ref(eq:solution) can be solved through gradient descent. This summarizes the approach followed in @wachter2017counterfactual which we refer to simply as **Wachter**, the name of the first author, in the remainder of this paper.

Many approaches for the generation of Algorithmic Recourse have been described in the literature since 2017. An October 2020 survey by Karimi et al. laid out 60 algorithms that have been proposed since 2014 [@karimi2020survey]. Another survey published around the same time by Verma et al. described 29 algorithms [@verma2020counterfactual]. Different approaches vary primarily in terms of the objective functions they impose, how they optimize said objective (from brute force through gradient-based approaches to graph traversal algorithms), and how they ensure that certain requirements for CE are met. Regarding the latter, the literature has produced an extensive list of desiderata each addressing different needs. To name but a few, we are interested in generating counterfactuals that are close [@wachter2017counterfactual], actionable [@ustun2019actionable], realistic [@joshi2019realistic, @schut2021generating], sparse, diverse [@mothilal2020explaining] and if possible causally founded [@karimi2021algorithmic].

Efforts so far have largely been directed at improving the quality of Counterfactual Explanations within a static context: given some pre-trained classifier $M: \mathcal{X} \mapsto \mathcal{Y}$, we are interested in generating one or multiple meaningful Counterfactual Explanations for some individual characterized by $x$. The ability of Counterfactual Explanations to handle dynamics like data and model shifts remains a largely unexplored research challenge at this point [@verma2020counterfactual]. We have been able to identify only one recent work by Upadhyay et al. that considers the implications of **exogenous** domain and model shifts in the context of AR [@upadhyay2021robust]. Exogenous shifts are strictly of external origin. For example, they might stem from data correction, temporal shifts or geospatial changes [@upadhyay2021robust]. Upadhyay et al. [@upadhyay2021robust] propose ROAR: a framework for Algorithmic Recourse that evidently improves robustness to such exogenous shifts.

As mentioned earlier, research has so far also generally focused on generating counterfactuals for single individuals or instances. We have been able to identify only one existing work that investigates black-box model behavior towards a group of individuals [@carrizosa2021generating]. The authors propose an optimization framework that generates collective counterfactuals. We provide a motivation for doing so from the perspective of endogenous macrodynamics of Algorithmic Recourse.


## Domain and Model Shifts {#related-shifts}

Much attention has been paid to the detection of dataset shifts â€“ situations where the distribution of data changes over time. Rabanser et al. suggest a framework to detect data drift from a minimal number of samples through the application of two-sample tests [@rabanser2019failing]. This task is a generalization of the anomaly detection problem for large datasets, which aims to answer the question if two sets of samples could have been generated from the same probability distribution. Numerous approaches to anomaly detection have been summarized [@chandola2009anomaly]. Another well-established research topic is that of concept drift: situations where external variables influence the patterns between the input and the output of a model [@widmer1996learning]. For instance, Gama et al. offer a review of the adaptive learning techniques which can handle concept drift [@gama2014survey]. Less previous work is available on the related topic of model drift: changes in model performance over time. Nelson et al. review how resistant different machine learning models are to the model drift [@nelson2015evaluating]. Ackerman et al. offer a method to detect changes in model performance when ground truth is not available [@ackerman2021machine]. 

In the context of Algorithmic Recourse, domain and model shifts were first brought up by the authors behind ROAR [@upadhyay2021robust]. In their work they refer to model shifts as simply any perturbation $\Delta$ to the parameters of the model in question: $M$. While this also sets the baseline for our analysis here, it is worth noting that in @upadhyay2021robust these perturbations are mechanically introduced. In contrast, we are interested in quantifying model shifts that arise endogenously as part of a dynamic recourse process. In addition to quantifying the magnitude of shifts $\Delta$, we aim to also analyse the characteristics of changes to the model, such as the position of the decision boundary and the overall decisiveness of the model. We have not been able to identify previous work on this topic.

## Benchmarking Counterfactual Generators {#related-benchmark}

Despite the large and growing number of approaches to counterfactual search, there have been surprisingly few benchmark studies that compare different methodologies. This may be partially due to limited software availability in this space. Recent work has started to address this gap: firstly, @deoliveira2021framework run a large benchmarking study using different algorithmic approaches and numerous tabular datasets; secondly, @pawelczyk2021carla introduce a Python framework---CARLA---that can be used to apply and benchmark different methodologies; finally, [`CounterfactualExplanations.jl`](https://github.com/pat-alt/CounterfactualExplanations.jl) [@altmeyer2022counterfactualexplanations] provides an extensible, fast and language-agnostic implementation in Julia. Since the experiments presented here involve extensive simulations, we have relied on and extended the Julia implementation due to the associated performance benefits. In particular, we have built a framework on top of [`CounterfactualExplanations.jl`](https://github.com/pat-alt/CounterfactualExplanations.jl) that extends the functionality from static benchmarks to simulation experiments: [`AlgorithmicRecourseDynamics.jl`]((https://anonymous.4open.science/r/AlgorithmicRecourseDynamics/README.md))^[The code is available from the following anonymized Github repository: [https://anonymous.4open.science/r/AlgorithmicRecourseDynamics/README.md](https://anonymous.4open.science/r/AlgorithmicRecourseDynamics/README.md).]. The core concepts implemented in that package reflect what is presented in Section \@ref(method-2) of this paper. 



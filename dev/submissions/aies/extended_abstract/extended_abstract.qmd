---
title: Dynamics in Algorithmic Recourse
subtitle: Trustworthy Artificial Intelligence for Finance and Economics
format:
    pdf:
        documentclass: acmart
        classoption: sigconf
        number-sections: true
        include-in-header: preamble.tex
        keep-tex: true
---

## Introduction

Recent advances in Artificial Intelligence (AI) have propelled its adoption in domains outside of Computer Science including Healthcare, Bioinformatics and Genetics. In Finance, Economics and other social sciences, applications of AI are still relatively limited. Decision-making in these fields has traditionally been guided by interpretable models that facilitate explanations. Explainability is crucial in this context, since decision-makers are typically held accountable by the public: central banks, for example, are heavily scrutinized for the policies they impose. It is therefore not surprising that practitioners and academics in these fields are reluctant to adopt AI technologies they cannot trust. Deep neural networks, for example, are generally considered as black boxes and therefore not trustworthy in a context that demands explanations. This PhD project is focused on exploring and developing methodologies that improve the trustworthiness of AI and thereby enable its application in Finance and Economics. 

The remainder of this extended abstract is structured as follows: @sec-main presents one of the research questions I have investigated during the first months of my PhD: how do counterfactual explanations handle dynamics? @sec-related places this work in the broader context of my research.

## Dynamics in Algorithmic Recourse {#sec-main}

**Counterfactual explanations** (CE) explain how inputs into a model need to change for it to produce different outputs. They are intuitive, simple and intrinsically linked to the potential outcome framework for causal inference, which social scientists are familiar with. Counterfactual explanations that involve realistic and actionable changes can be used for the purpose of **Algorithmic Recourse** (AR) to help individuals who face adverse outcomes. An example relevant to the Finance and Economics domain is consumer credit: in this context AR can be used to guide individuals in improving their creditworthiness, should they have previously been denied access to credit based on an automated decision-making system. 

Existing work on CE and AR has largely been limited to the static setting: given some classifier $M: \mathcal{X} \mapsto \mathcal{Y}$ we are interested in finding close [@wachter2017counterfactual], actionable [@ustun2019actionable], realistic [@joshi2019towards, @schut2021generating], sparse, diverse [@mothilal2020explaining] and ideally causally founded counterfactual explanations [@karimi2021algorithmic] for some individual $x$. The ability of counterfactual explanations to handle dynamics like data and model shifts remains a largely unexplored research challenge at this point [@verma2020counterfactual]. Only one recent work considers the implications of **exogenous** domain and model shifts [@upadhyay2021towards]. The authors propose a simple minimax objective, that minimizes the counterfactual loss function for a maximal model shift. They show that their approach yields more robust counterfactuals in this context than existing approaches. 

This project investigates **endogenous** domain and model shifts, that is shifts that occur when AR is actually implemented by a proportion of individuals and the classifier is updated in response. @fig-dynamics illustrates this idea for a binary problem involving a probabilistic classifier and the counterfactual generator proposed by @wachter2017counterfactual: the implementation of AR for a subset of individuals leads to a domain shift (b), which in turn triggers a model shift (c). As this game of implementing AR and updating the classifier is repeated, the decision boundary moves away from training samples that were originally in the target class (d). 

These dynamics may be problematic. As the decision boundary moves in the direction of the non-target class, counterfactual paths become shorter: in the loan example, individuals that previously would have been denied credit based on their input features are suddenly considered as creditworthy. Average default risk across all borrowers can therefore be expected to increase. Conversely, lenders that anticipate such dynamics may choose to deny credit to individuals that have implemented AR, thereby compromising the validity of AR. 

To the best of my knowledge this is the first work investigating endogenous dynamics in AR. Through future experiments I want to investigate how this phenomenon plays out across different benchmark datasets including German credit, Boston Housing and COMPAS.^[These benchmark datasets have their issues and controversies, which is one of the challenges I would like to discuss at AIES.] Furthermore, I want to assess to what extent the magnitude and direction of domain and model shifts depends on the choice of the counterfactual generator. To this end, I am currently supervising a group of undergraduate students, who are tackling some of these tasks in their final-year research project. 

![Dynamics in Algorithmic Recourse: we have a simple Bayesian model trained for binary classification (a); the implementation of AR for a random subset of individuals leads to a domain shift (b); as the classifier is retrained we observe a model shift (c); as this process is repeated, the decision boundary moves away from the target class (d).](www/poc.png){#fig-dynamics fig.pos="h" width=45%}

## Related and Future Work {#sec-related}

### Benchmarking CE in Julia

Until recently there existed only one open-source library that provides a unifying approach to generate and benchmark counterfactual explanations for Python models [@pawelczyk2021carla]. To address this limitation I have developed [CounterfactualExplanations.jl](https://www.paltmeyer.com/CounterfactualExplanations.jl/stable/): a Julia package that can be used to generate counterfactual explanations for models developed and trained not only in Julia, but also in other popular programming languages. The package and companion paper are pending acceptance for a main talk at [JuliaCon '22](https://juliacon.org/2022/). 

### Probabilistic Methods for Realistic CE

To ensure that the generated counterfactuals are realistic it helps to understand which input-output pairs are likely to occur under the data generating process. To this end, previous work has either relied on generative models or restricted the analysis to probabilistic classifiers that incorporate uncertainty in their predictions. While the former approach is more generally applicable, the latter is computationally more efficient. In future work, I want to explore how recent advances in post-hoc uncertainty quantification, most notably Laplace Redux [@daxberger2021laplace], can be leveraged to generate realistic and unambiguous counterfactual explanations for any model.^[For some initial work on this see my Julia implementation of Laplace Redux: [BayesLaplace.jl](https://www.paltmeyer.com/BayesLaplace.jl/dev/).] With respect to the work-in-progress presented here, I expect that these efforts may help in mitigating endogenous domain and model shifts.

## References
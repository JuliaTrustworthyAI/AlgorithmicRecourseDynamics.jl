{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module Models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogLevel(1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../src/load.jl\")\n",
    "using AlgorithmicRecourse, MLDatasets, Flux\n",
    "using Plots, PlotThemes\n",
    "theme(:juno)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, Statistics\n",
    "X = BostonHousing.features()\n",
    "y = BostonHousing.targets()\n",
    "y = y .>= median(y); # binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off we will just train a single neural network for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data and model:\n",
    "using Random\n",
    "Random.seed!(1234)\n",
    "# using StatsBase\n",
    "dt = fit(ZScoreTransform, X, dims=2)\n",
    "StatsBase.transform!(dt, X)\n",
    "xs = Flux.unstack(X,2)\n",
    "data = zip(xs,y)\n",
    "nn = Models.build_model(input_dim=size(X)[1], n_hidden=100)\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves decent training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model:\n",
    "using Flux.Optimise: update!, ADAM\n",
    "using Statistics, StatsBase\n",
    "opt = ADAM()\n",
    "epochs = 100\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "accuracy(data) = sum(map(d ->round.(Flux.σ.(nn(d[1]))) .== d[2], data))[1]/length(data)\n",
    "\n",
    "using Plots\n",
    "anim = Animation()\n",
    "avg_l = [avg_loss(data)]\n",
    "p1 = scatter( ylim=(0,avg_l[1]), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Average loss\")\n",
    "acc = [accuracy(data)]\n",
    "p2 = scatter( ylim=(0.5,1), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Accuracy\")\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, params(nn), gs)\n",
    "  end\n",
    "  avg_l = vcat(avg_l,avg_loss(data))\n",
    "  plot!(p1, [0:epoch], avg_l, color=1)\n",
    "  scatter!(p1, [0:epoch], avg_l, color=1)\n",
    "  acc = vcat(acc,accuracy(data))\n",
    "  plot!(p2, [0:epoch], acc, color=1)\n",
    "  scatter!(p2, [0:epoch], acc, color=1)\n",
    "  plt=plot(p1,p2, size=(600,300))\n",
    "  frame(anim, plt)\n",
    "end\n",
    "\n",
    "gif(anim, \"www/boston_housing_single_nn.gif\", fps=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing_single_nn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build and train a deep ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 50\n",
    "𝓜 = Models.build_ensemble(K,kw=(input_dim=size(X)[1], n_hidden=100));\n",
    "𝓜, anim = Models.forward(𝓜, data, opt, n_epochs=30, plot_every=10); # fit the ensemble\n",
    "gif(anim, \"www/boston_housing_ensemble_loss.gif\", fps=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "Random.seed!(1234)\n",
    "x̅ = X[:,(y.==0)'][:,rand(1:length((y.==0)'))] # select individual sample\n",
    "x̅ = reshape(x̅, (length(x̅),1))\n",
    "γ = 0.75\n",
    "target=1.0\n",
    "𝑴=Classifiers.FittedEnsemble(𝓜);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = GreedyGenerator(1,20,:logitbinarycrossentropy,nothing)\n",
    "recourse = generate_recourse(generator, x̅, 𝑴, target, γ); # generate recourse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

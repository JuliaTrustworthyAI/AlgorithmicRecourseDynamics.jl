# Experiments {#empirical-2}

Below we first present our main findings with respect to the presence of endogenous macrodynamics in Algorithmic Recourse. We then go on to introduce and test a number of potential mitigation strategies.

## Endogenous Macrodynamics

In light of the huge number of experiments we have conducted, we shall start this section off with a few high-level observations. Across all datasets (synthetic and real), classifiers and counterfactual generators we observe either most or all of the following dynamics at varying degrees:

- Statistically significant domain and model shift as measured by MMD. 
- A deterioration in out-of-sample model performance as measured by the F-Score evaluated on a test sample. In many cases this drop in performance is substantial.
- Significant perturbations to the model parameters as well as an increase in the model's decisiveness.
- Disagreement between the original and retrained model, in some cases large.

There is also some clear heterogeneity across the results: 

- The observed, adverse dynamics are generally speaking of the highest magnitude for the simple linear classifier. Differences in results for the MLP and Deep Ensemble are mostly negligible. 
- The reduction in model performance appears to be most severe when classes are not perfectly separable.
- With the exception of the Greedy generator, all other generators generally perform somewhat better than Wachter overall as expected. 

Granular tables and visualizations summarizing all of our experimental results are published in the supplementary appendix. Here we will zoom in on illustrative examples that nicely reflect some of the broader patterns we have observed and listed above. Figure \@ref(fig:syn) presents a small subset of our results for the synthetic dataset with overlapping classes. It shows the resulting values for some of our evaluation metrics at the end of the experiment, so after all $T=50$ rounds, along with error bars indicating the variation across folds. The top row shows the estimated domain shifts. While it is not straight-forward to interpret the exact magnitude of MMD, we can see clearly that the values are different from zero and there is essentially no variation across our five folds. With respect to the domain shifts, the Greedy generator actually induces the smallest shifts. In general, we have observed the opposite. The second row shows the estimated model shifts, where here we have used the meshgrid approach explained earlier. As with the domain shifts, the observed values are clearly different from zero and variation across folds is once again small. In this case, the results for this particular dataset very much reflect the broader patterns we have observed: Latent Space generators induce the smallest shifts, followed by DiCE, then Wachter and finally Greedy. The same broad pattern also emerges in the bottom row: we observe the smallest deterioration in model performance for Latent Space generators, albeit still a reduction in the F-Score of around 5 percentage points on average. 

```{r syn, fig.cap="Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a meshgrid of points. Error bars indicate the standard deviation across folds."}
knitr::include_graphics("www/synthetic_results.png")
```

Turning to the real-world data next ...

```{r real, fig.cap="Results for real-world datasets."}
knitr::include_graphics("www/real_world_results.png")
```


{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module Models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogLevel(1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"../src/load.jl\")\n",
    "using AlgorithmicRecourse, MLDatasets, Flux\n",
    "using Plots, PlotThemes\n",
    "theme(:juno)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, Statistics\n",
    "X = BostonHousing.features()\n",
    "y = BostonHousing.targets()\n",
    "y = y .>= median(y); # binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off we will just train a single neural network for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data and model:\n",
    "using Random\n",
    "Random.seed!(1234)\n",
    "minib_size = 100\n",
    "data = Flux.Data.DataLoader((X,y),batchsize=minib_size)\n",
    "minib_actual_sizes = map(mb -> length(mb[2]), data)\n",
    "nn = Models.build_model(input_dim=size(X)[1], n_hidden=100)\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves decent training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model:\n",
    "using Flux.Optimise: update!, ADAM\n",
    "using Statistics, StatsBase\n",
    "opt = ADAM()\n",
    "epochs = 50\n",
    "avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "accuracy(data) = mean(map(minib -> sum(round.(Flux.œÉ.(nn(minib[1]))) .== minib[2])/length(minib[2]),data), weights(minib_actual_sizes))\n",
    "\n",
    "using Plots\n",
    "anim = Animation()\n",
    "avg_l = [avg_loss(data)]\n",
    "p1 = scatter( ylim=(0,avg_l[1]), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Average loss\")\n",
    "acc = [accuracy(data)]\n",
    "p2 = scatter( ylim=(0.5,1), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Accuracy\")\n",
    "\n",
    "for epoch = 1:epochs\n",
    "  for d in data\n",
    "    gs = gradient(params(nn)) do\n",
    "      l = loss(d...)\n",
    "    end\n",
    "    update!(opt, params(nn), gs)\n",
    "  end\n",
    "  avg_l = vcat(avg_l,avg_loss(data))\n",
    "  plot!(p1, [0:epoch], avg_l, color=1)\n",
    "  scatter!(p1, [0:epoch], avg_l, color=1)\n",
    "  acc = vcat(acc,accuracy(data))\n",
    "  plot!(p2, [0:epoch], acc, color=1)\n",
    "  scatter!(p2, [0:epoch], acc, color=1)\n",
    "  plt=plot(p1,p2, size=(600,300))\n",
    "  frame(anim, plt)\n",
    "end\n",
    "\n",
    "gif(anim, \"www/boston_housing_single_nn.gif\", fps=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing_single_nn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build and train a deep ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2\n",
    "ùìú = Models.build_ensemble(K,kw=(input_dim=size(X)[1], n_hidden=100));\n",
    "ùìú, anim = Models.forward(ùìú, data, opt, n_epochs=30, plot_every=10); # fit the ensemble\n",
    "gif(anim, \"www/boston_housing_ensemble_loss.gif\", fps=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing_ensemble_loss.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "Random.seed!(1234)\n",
    "xÃÖ = X[:,(y.==0)'][:,rand(1:length((y.==0)'))] # select individual sample\n",
    "xÃÖ = reshape(xÃÖ, (length(xÃÖ),1))\n",
    "Œ≥ = 0.75\n",
    "target=1.0\n",
    "ùë¥=Classifiers.FittedEnsemble(ùìú);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924901185770751"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(round.(AlgorithmicRecourse.Models.probs(ùë¥,X)) .== y)/506"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1√ó506 Matrix{Float64}:\n",
       " 0.567293  0.540872  0.671709  0.727858  ‚Ä¶  0.569005  0.554362  0.560515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AlgorithmicRecourse.Models.probs(ùë¥,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = GreedyGenerator(1,20,:logitbinarycrossentropy,nothing)\n",
    "# recourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥, T=0); # generate recourse\n",
    "generator = GenericGenerator(0.1,0.1,1e-5,:logitbinarycrossentropy,nothing)\n",
    "recourse = generate_recourse(generator, xÃÖ, ùë¥, target, Œ≥); # generate recourse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1√ó506 Matrix{Float64}:\n",
       " 0.567293  0.540872  0.671709  0.727858  ‚Ä¶  0.569005  0.554362  0.560515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "AlgorithmicRecourse.Models.probs(ùë¥,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlgorithmicRecourse.Recourse([0.18337; 0.0; ‚Ä¶ ; 344.05; 23.97], NaN, [0.18337 0.0 ‚Ä¶ 344.05 23.97; 0.18337 0.0 ‚Ä¶ 344.05 23.97], GreedyGenerator(1.0, 20, :logitbinarycrossentropy, nothing), [0.18337; 0.0; ‚Ä¶ ; 344.05; 23.97], 0.0, Main.Classifiers.FittedEnsemble(Chain{Tuple{Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, BatchNorm{typeof(relu), Vector{Float32}, Float32, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}, BatchNorm{typeof(relu), Vector{Float32}, Float32, Vector{Float32}}, Dense{typeof(identity), Matrix{Float32}, Vector{Float32}}}}[Chain(Dense(13, 100), BatchNorm(100, relu), Dense(100, 100), BatchNorm(100, relu), Dense(100, 1)), Chain(Dense(13, 100), BatchNorm(100, relu), Dense(100, 100), BatchNorm(100, relu), Dense(100, 1))]), 1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recourse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

# Related Work {#sec-related}

In this Section we provide a review of the relevant literature. First, @sec-related-recourse discusses the existing research within the domain of counterfactual explanations and algorithmic recourse. Then, @sec-related-shifts presents some of the previous work on the measurement of dataset and model shifts.

## Algorithmic Recourse {#sec-related-recourse}

A framework for Counterfactual Explanations was first proposed in 2017 by @wachter2017counterfactual and has served as the baseline for most methodologies that have been proposed since then. Let $M: \mathcal{X} \mapsto \mathcal{Y}$ denote some pre-trained model that maps from inputs $X \in \mathcal{X}$ to outputs $Y \in \mathcal{Y}$. Then we are interested in minimizing the complexity or effort $H=h(x\prime)$ associated with moving an individual $x$ to a counterfactual state $x\prime$ such that the predicted outcome $M(x\prime)$ corresponds to some target outcome $t$:

$$
\min_{x\prime \in \mathcal{x}} c(x\prime) \ \ \ \mbox{s. t.} \ \ \ M(x\prime) = t
$$ {#eq-obj}

For implementation purposes, @eq-obj is typically approximated through regularization:

$$
x\prime = \arg \min_{x\prime}  \ell(M(x\prime),t) + \lambda h(x\prime)
$$ {#eq-solution}

In the baseline work and many subsequent approaches the complexity function $h: \mathcal{X} \mapsto \mathbb{R}$ is proxied by some distance metric based on the simple intuition that large perturbations of $x$ are costly. 

Many approaches for the generation of algorithmic recourse have been described in the literature. An October 2020 survey by Karimi et al. layed out 60 algorithms that have been proposed since 2014 [@karimi2020survey]. Another survey published around the same time by Verma et al. described 29 algorithms [@verma2020counterfactual]. Different approaches vary primarily in terms of the objective functions they impose, how they optimize said objective (from brute force through gradient-based approaches to graph traversal algorithms), and how the ensure that certain requirements for CE are met. Regarding the latter, the literature has produced an extensive list of desiderata each addressing different needs. To name but a few, we are interested in generating counterfactuals that close [@wachter2017counterfactual], actionable [@ustun2019actionable], realistic [@joshi2019towards, @schut2021generating], sparse, diverse [@mothilal2020explaining] and if possible causally founded [@karimi2021algorithmic].

Efforts so far have largely been directed at improving the quality of counterfactual explanations within a static context: given some pre-trained classifier $M: \mathcal{X} \mapsto \mathcal{Y}$ we are interested in generating one or multiple meaningful counterfactual explanations for some individual characterized by $x_i$. The ability of counterfactual explanations to handle dynamics like data and model shifts remains a largely unexplored research challenge at this point [@verma2020counterfactual]. We have been able to identify only one recent work that considers the implications of **exogenous** domain and model shifts in the context of AR [@upadhyay2021towards]. Exogenous shifts are strictly of external origin. For example, they might stem from data correction, temporal shifts or geospatial changes [@upadhyay2021towards]. The authors of [@upadhyay2021towards] propose framework for algorithmic recourse (ROAR) that evidently improves robustness to such exogenous shifts.

As mentioned earlier, research has so far also generally focused on generating counterfactuals for single individuals or instances. We have been able to identify only one existing work that investigates black-box model behavior towards a group of individuals [@carrizosa2021generating]. The authors propose an optimization framework that generates collective counterfactuals. We provide a motivation for doing so from the perspective of endogenous macrodynamics of algorithmic recourse. 

## Domain and Model Shifts {#sec-related-shifts}

Much attention has been paid to the detection of dataset shifts – situations where the distribution of data changes over time. Rabanser et al. suggest a framework to detect data drift from a minimal number of samples through the application of two-sample tests [@rabanser2019failing]. This task is a generalization of the anomaly detection problem for large datasets, which aims to answer the question if two sets of samples could have been generated from the same probability distribution. Numerous approaches to anomaly detection have been summarized [@chandola2009anomaly]. Another well-established research topic is that of concept drift – situations where external variables influence the patterns between the input and the output of a model [@widmer1996learning]. For instance, Gama et al. offer a review of the adaptive learning techniques which can handle concept drift [@gama2014survey]. Less previous work is available on the related topic of model drift - changes in model performance over time. Nelson et al. review how resistant different machine learning models are to the model drift [@nelson2015evaluating]. Ackerman et al. offer a method to detect changes in model performance when ground truth is not available [@ackerman2021machine]. 

In the context of algorithmic recourse, domain and model shifts were first brought up by the authors behind ROAR [@upadhyay2021towards]. In their work they refer to model shifts as simply any perturbation $\Delta$ to the parameters of the model in question: $M$. While this also sets the baseline for our analysis here, it is worth noting that in @upadhyay2021towards these perturbations are mechanically introduced. In contrast we are interested in quantifying model shifts that arise endogenously as part of a dynamic recourse process. In addition to quantifying the magnitude of shifts $\Delta$, we aim to also analyse the characteristics of changes to the model, such as the position of the decision boundary and the overall decisiveness of the model. We have not been able to identify previous work on this topic.

## Benchmarking Counterfactual Generators {#sec-related-benchmark}

Despite the large and growing number of approaches to counterfactual search there have been surprisingly few benchmark studies that compare different methodologies. This may be partially due to limited software availability in this space. Recent work has started to address this gap: firstly, @de2021framework run a large benchmarking study using different algorithmic aproaches and numerous tabular datasets; secondly, @pawelczyk2021carla introduce a Python framework that can be used to apply and benchmark different methodologies; finally, @altmeyer2022CounterfactualExplanations provides an extensible, fast and language-agnostic implementation in Julia. Since the experiments presented here involve extensive simulations, we have relied on and extended the Julia implementation due to the associated performance benefits. 



<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Endogenous Macrodynamics in Algorithmic Recourse</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Endogenous Macrodynamics in Algorithmic Recourse</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  
<div>
  <div class="abstract">
    <div class="abstract-title">Abstract</div>
    <p>Existing work on Counterfactual Explanations (CE) and Algorithmic Recourse (AR) has largely been limited to the static setting and focused on single individuals: given some estimated model the goal is to find valid counterfactuals for individual instance that fulfill various desiderata. The ability of such counterfactuals to handle dynamics like data and model drift remains a largely unexplored research challenge at this point. There has also been surprisingly little work on the related question of how the actual implementation of recourse by one individual may affect other individuals. Through this work we aim to close that gap by systematizing and extending existing knowledge. We first show that many of the existing methodologies can be collectively described by a generalized framework. We then argue that the existing framework fails to account for a hidden external cost of recourse, that only reveals itself when studying the endogenous dynamics of recourse at the group level. Through simulation experiments involving various popular counterfactual generators and several benchmark datasets, we generate a total XX million Counterfactual Explanations and study the resulting domain and model shifts. We find that the induced shifts are substantial enough to likely impede the applicability Algorithmic Recourse in practice. Fortunately, we find various potential mitigation strategies that can be used in combination with existing approaches. Our simulation framework for studying recourse dynamics is fast and open-sourced.</p>
  </div>
</div>

</header>

<section id="sec-intro" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Introduction</h1>
<p>Recent advances in Artificial Intelligence (AI) have propelled its adoption in scientific domains outside of Computer Science including Healthcare, Bioinformatics, Genetics and the Social Sciences. While this has in many cases brought benefits in terms of efficiency, state-of-the-art models like Deep Neural Networks (DNN) have also given rise a new type of problem in the context of data-driven decision-making. They are essentially <strong>black boxes</strong>: so complex, opaque and underspecified in the data that it is often impossible to understand how they actually arrive at their decision without auxiliary tools. Despite this shortcoming, black-box models have grown in popularity in recent years and have at times created undesirable societal outcomes <span class="citation" data-cites="o2016weapons"><a href="#ref-o2016weapons" role="doc-biblioref">[1]</a></span>. The scientific community has tackled this issue from two different angles: while some have appealed for a strict focus on inherently interpretable models <span class="citation" data-cites="rudin2019stop"><a href="#ref-rudin2019stop" role="doc-biblioref">[2]</a></span>, others have investigated different ways to explain the behaviour of black-box models. These two sub-domains can be broadly referred to as <strong>interpretable AI</strong> and <strong>explainable AI</strong> (XAI), respectively.</p>
<p>Among the approaches to XAI that have recently grown in popularity are <strong>Counterfactual Explanations</strong> (CE). They explain how inputs into a model need to change for it to produce different outputs. Counterfactual Explanations that involve realistic and actionable changes can be used for the purpose of <strong>Algorithmic Recourse</strong> (AR) to help individuals who face adverse outcomes. An example relevant to the Social Sciences is consumer credit: in this context, AR can be used to guide individuals in improving their creditworthiness, should they have previously been denied access to credit based on an automated decision-making system. A meaningful recourse recommendation for a denied applicant could be: <em>“If your net savings rate had been 10% of your monthly income instead of the actual 8%, your application would have been successful. See if you can temporarily cut down on consumption.”</em> In the remainder of this paper we will use both terminologies - recourse and counterfactual - interchangeably to refer to situations where counterfactuals are generated with the intent to provide individual recourse.</p>
<p>Existing work in this field has largely worked in a static setting: various approaches have been proposed to generate counterfactuals for a given individual that is subject to some pre-trained model. More recent work has compared different approaches within this static setting <span class="citation" data-cites="pawelczyk2021carla"><a href="#ref-pawelczyk2021carla" role="doc-biblioref">[3]</a></span>. In this work, we go one step further and ask ourselves: what happens if recourse is provided and implemented repeatedly? What types of dynamics are introduced and how do different counterfactual generators compare in this context?</p>
<p>Research on Algorithmic Recourse has also so far typically addressed the issue from the perspective of one single individual and has indeed been referred to as <strong>individual recourse</strong> in some places. Arguably though, most real-world applications that warrant Algorithmic Recourse involve potentially large groups of individuals typically competing for scarce resources. Our work demonstrates that in such scenarios, choices made by or for one single individual are likely to affect the broader collective of individuals in ways that current approaches to AR fail to account for. More specifically, we argue that a strict focus on minimizing the private costs faced by individuals may be too narrow an objective.</p>
<p><a href="#fig-poc">Figure&nbsp;1</a> illustrates this idea for a binary problem involving a probabilistic classifier and the counterfactual generator proposed by <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span>: the implementation of AR for a subset of individuals leads to a domain shift (b), which in turn triggers a model shift (c). As this game of implementing AR and updating the classifier is repeated, the decision boundary moves away from training samples that were originally in the target class (d). We refer to these types of dynamics as <strong>endogenous</strong> because they are induced by the implementation of recourse itself. The term <strong>macrodynamics</strong> is borrowed from the economics literature and used to describe processes involving whole groups or societies.</p>
<div id="fig-poc" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/poc.png" class="img-fluid figure-img" data-fig.pos="h" style="width:45.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 1: Dynamics in Algorithmic Recourse: we have a simple linear classifier trained for binary classification (a); the implementation of AR for a random subset of individuals leads to a noticable domain shift (b); as the classifier is retrained we observe a corresponding model shift (c); as this process is repeated, the decision boundary moves away from the target class (d).</figcaption><p></p>
</figure>
</div>
<p>We think that these types of endogenous dynamics may be problematic and warrant our attention. Firstly, model shifts may inadvertently change classification outcomes for individuals who never received and implemented recourse. Secondly and relatedly, we observe in <a href="#fig-poc">Figure&nbsp;1</a> that as the decision boundary moves in the direction of the non-target class, counterfactual paths become shorter: in the consumer credit example, individuals that previously would have been denied credit based on their input features are suddenly considered as creditworthy. Average default risk across all borrowers can therefore be expected to increase. Conversely, lenders that anticipate such dynamics may choose to refrain from offering recourse (and hence credit) to more than just a tiny share of individuals. In that latter and perhaps more likely scenario, the probability of being offered recourse decreases with every individual that implements recourse: in other words, the actions of first-movers exert a negative externality on future would-be borrowers.</p>
<p>To the best of our knowledge this is the first work investigating endogenous macrodynamics in AR. Our contributions to the state of knowledge are as follows: firstly, we posit a compelling argument that calls for a novel perspective on Algorithmic Recourse extending our focus from single individuals to groups. Secondly, we introduce an experimental framework extending previous work by <span class="citation" data-cites="altmeyer2022CounterfactualExplanations"><a href="#ref-altmeyer2022CounterfactualExplanations" role="doc-biblioref">[5]</a></span>, which enables us to study macrodynamics of Algorithmic Recourse through simulations that can be fully parallelized. Thirdly, we use this framework to provide a first in-depth analysis of endogenous recourse dynamics induced by various popular counterfactual generators including <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span>, <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>, <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span>, <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> and <span class="citation" data-cites="antoran2020getting"><a href="#ref-antoran2020getting" role="doc-biblioref">[9]</a></span>. To this end we propose a number of novel evaluation metrics that can be used to quantify and benchmark the macrodynamics introduced by the different generators. Finally, we also discuss what drives endogenous dynamics and propose strategies to mitigate them.</p>
<p>The remainder of the paper is structured as follows: <a href="#sec-related">Section&nbsp;2</a> places our work in the broader context of related literature. <a href="#sec-method">Section&nbsp;3</a> posits a generalized framework for gradient-based Algorithmic Recourse and introduces the notion of hidden external costs. <a href="#sec-method-2">Section&nbsp;4</a> sets out our experimental framework for modeling endogenous macrodynamics in AR. <a href="#sec-empirical">Section&nbsp;5</a> presents our experimental setup, including the data, classifiers and counterfactual generators that we have employed. <a href="#sec-empirical-2">Section&nbsp;6</a> presents the results for synthetic and real-world datasets along with evidence for the effectiveness of various proposed mitigation strategies. Our findings are then discussed in the broader context of the literature in <a href="#sec-discussion">Section&nbsp;8</a>, before pointing to some of the limitations of our work as well as avenues for future research in <a href="#sec-limit">Section&nbsp;9</a>. Finally, <a href="#sec-conclusion">Section&nbsp;10</a> concludes.</p>
</section>
<section id="sec-related" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Background</h1>
<p>In this Section we provide a review of the relevant literature. First, <a href="#sec-related-recourse">Section&nbsp;2.1</a> discusses the existing research within the domain of Counterfactual Explanations and Algorithmic Recourse. Then, <a href="#sec-related-shifts">Section&nbsp;2.2</a> presents some of the previous work on the measurement of dataset and model shifts.</p>
<section id="sec-related-recourse" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-related-recourse"><span class="header-section-number">2.1</span> Algorithmic Recourse</h2>
<p>A framework for Counterfactual Explanations was first proposed in 2017 by <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span> and has served as the baseline for most methodologies that have been proposed since then. Let <span class="math inline">\(M: \mathcal{X} \mapsto \mathcal{Y}\)</span> denote some pre-trained model that maps from inputs <span class="math inline">\(X \in \mathcal{X}\)</span> to outputs <span class="math inline">\(Y \in \mathcal{Y}\)</span>. Then we are interested in minimizing the cost<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math inline">\(H=h(x\prime)\)</span> incurred by individual <span class="math inline">\(x\)</span> when moving to a counterfactual state <span class="math inline">\(x\prime\)</span> such that the predicted outcome <span class="math inline">\(M(x\prime)\)</span> corresponds to some target outcome <span class="math inline">\(y^*\)</span>:</p>
<p><span id="eq-obj"><span class="math display">\[
\min_{x\prime \in \mathcal{x}} h(x\prime) \ \ \ \mbox{s. t.} \ \ \ M(x\prime) = t
\tag{1}\]</span></span></p>
<p>For implementation purposes, <a href="#eq-obj">Equation&nbsp;1</a> is typically approximated through regularization:</p>
<p><span id="eq-solution"><span class="math display">\[
x\prime = \arg \min_{x\prime}  \ell(M(x\prime),y^*) + \lambda h(x\prime)
\tag{2}\]</span></span></p>
<p>In the baseline work <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span>, the cost function <span class="math inline">\(h: \mathcal{X} \mapsto \mathbb{R}\)</span> is proxied by some distance metric based on the simple intuition that perturbations of <span class="math inline">\(x\)</span> are costly to the individual. For models that are differentiable and produce smooth predictions, <a href="#eq-solution">Equation&nbsp;2</a> can be solved through gradient descent. This summarizes the approach followed in <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span> which we shall refer to simply as <strong>Wachter</strong> - the name of the first author - in the remainder of this paper.</p>
<p>Many approaches for the generation of Algorithmic Recourse have been described in the literature since 2017. An October 2020 survey by Karimi et al.&nbsp;layed out 60 algorithms that have been proposed since 2014 <span class="citation" data-cites="karimi2020survey"><a href="#ref-karimi2020survey" role="doc-biblioref">[10]</a></span>. Another survey published around the same time by Verma et al.&nbsp;described 29 algorithms <span class="citation" data-cites="verma2020counterfactual"><a href="#ref-verma2020counterfactual" role="doc-biblioref">[11]</a></span>. Different approaches vary primarily in terms of the objective functions they impose, how they optimize said objective (from brute force through gradient-based approaches to graph traversal algorithms), and how the ensure that certain requirements for CE are met. Regarding the latter, the literature has produced an extensive list of desiderata each addressing different needs. To name but a few, we are interested in generating counterfactuals that close <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span>, actionable <span class="citation" data-cites="ustun2019actionable"><a href="#ref-ustun2019actionable" role="doc-biblioref">[12]</a></span>, realistic <span class="citation" data-cites="joshi2019towards"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>, sparse, diverse <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> and if possible causally founded <span class="citation" data-cites="karimi2021algorithmic"><a href="#ref-karimi2021algorithmic" role="doc-biblioref">[13]</a></span>.</p>
<p>Efforts so far have largely been directed at improving the quality of Counterfactual Explanations within a static context: given some pre-trained classifier <span class="math inline">\(M: \mathcal{X} \mapsto \mathcal{Y}\)</span>, we are interested in generating one or multiple meaningful Counterfactual Explanations for some individual characterized by <span class="math inline">\(x\)</span>. The ability of Counterfactual Explanations to handle dynamics like data and model shifts remains a largely unexplored research challenge at this point <span class="citation" data-cites="verma2020counterfactual"><a href="#ref-verma2020counterfactual" role="doc-biblioref">[11]</a></span>. We have been able to identify only one recent work that considers the implications of <strong>exogenous</strong> domain and model shifts in the context of AR <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. Exogenous shifts are strictly of external origin. For example, they might stem from data correction, temporal shifts or geospatial changes <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. The authors of <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span> propose ROAR - a framework for Algorithmic Recourse that evidently improves robustness to such exogenous shifts.</p>
<p>As mentioned earlier, research has so far also generally focused on generating counterfactuals for single individuals or instances. We have been able to identify only one existing work that investigates black-box model behavior towards a group of individuals <span class="citation" data-cites="carrizosa2021generating"><a href="#ref-carrizosa2021generating" role="doc-biblioref">[15]</a></span>. The authors propose an optimization framework that generates collective counterfactuals. We provide a motivation for doing so from the perspective of endogenous macrodynamics of Algorithmic Recourse.</p>
</section>
<section id="sec-related-shifts" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-related-shifts"><span class="header-section-number">2.2</span> Domain and Model Shifts</h2>
<p>Much attention has been paid to the detection of dataset shifts – situations where the distribution of data changes over time. Rabanser et al.&nbsp;suggest a framework to detect data drift from a minimal number of samples through the application of two-sample tests <span class="citation" data-cites="rabanser2019failing"><a href="#ref-rabanser2019failing" role="doc-biblioref">[16]</a></span>. This task is a generalization of the anomaly detection problem for large datasets, which aims to answer the question if two sets of samples could have been generated from the same probability distribution. Numerous approaches to anomaly detection have been summarized <span class="citation" data-cites="chandola2009anomaly"><a href="#ref-chandola2009anomaly" role="doc-biblioref">[17]</a></span>. Another well-established research topic is that of concept drift – situations where external variables influence the patterns between the input and the output of a model <span class="citation" data-cites="widmer1996learning"><a href="#ref-widmer1996learning" role="doc-biblioref">[18]</a></span>. For instance, Gama et al.&nbsp;offer a review of the adaptive learning techniques which can handle concept drift <span class="citation" data-cites="gama2014survey"><a href="#ref-gama2014survey" role="doc-biblioref">[19]</a></span>. Less previous work is available on the related topic of model drift - changes in model performance over time. Nelson et al.&nbsp;review how resistant different machine learning models are to the model drift <span class="citation" data-cites="nelson2015evaluating"><a href="#ref-nelson2015evaluating" role="doc-biblioref">[20]</a></span>. Ackerman et al.&nbsp;offer a method to detect changes in model performance when ground truth is not available <span class="citation" data-cites="ackerman2021machine"><a href="#ref-ackerman2021machine" role="doc-biblioref">[21]</a></span>.</p>
<p>In the context of Algorithmic Recourse, domain and model shifts were first brought up by the authors behind ROAR <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. In their work they refer to model shifts as simply any perturbation <span class="math inline">\(\Delta\)</span> to the parameters of the model in question: <span class="math inline">\(M\)</span>. While this also sets the baseline for our analysis here, it is worth noting that in <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span> these perturbations are mechanically introduced. In contrast we are interested in quantifying model shifts that arise endogenously as part of a dynamic recourse process. In addition to quantifying the magnitude of shifts <span class="math inline">\(\Delta\)</span>, we aim to also analyse the characteristics of changes to the model, such as the position of the decision boundary and the overall decisiveness of the model. We have not been able to identify previous work on this topic.</p>
</section>
<section id="sec-related-benchmark" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="sec-related-benchmark"><span class="header-section-number">2.3</span> Benchmarking Counterfactual Generators</h2>
<p>Despite the large and growing number of approaches to counterfactual search, there have been surprisingly few benchmark studies that compare different methodologies. This may be partially due to limited software availability in this space. Recent work has started to address this gap: firstly, <span class="citation" data-cites="de2021framework"><a href="#ref-de2021framework" role="doc-biblioref">[22]</a></span> run a large benchmarking study using different algorithmic aproaches and numerous tabular datasets; secondly, <span class="citation" data-cites="pawelczyk2021carla"><a href="#ref-pawelczyk2021carla" role="doc-biblioref">[3]</a></span> introduce a Python framework - CARLA - that can be used to apply and benchmark different methodologies; finally, <code>CounterfactualExplanations.jl</code> <span class="citation" data-cites="altmeyer2022CounterfactualExplanations"><a href="#ref-altmeyer2022CounterfactualExplanations" role="doc-biblioref">[5]</a></span> provides an extensible, fast and language-agnostic implementation in Julia. Since the experiments presented here involve extensive simulations, we have relied on and extended the Julia implementation due to the associated performance benefits. In particular, we have built a framework on top of <code>CounterfactualExplanations.jl</code> that extends the functionality from static benchmarks to simulation experiments: <code>AlgorithmicRecourseDynamics.jl</code><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. The core concepts implemented in that package reflect what is presented in section <a href="#sec-method-2">Section&nbsp;4</a> of this paper.</p>
</section>
</section>
<section id="sec-method" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Gradient-Based Recourse Revisited</h1>
<p>In this section we first set out a generalized framework for gradient-based counterfactual search in <a href="#sec-method-general">Section&nbsp;3.1</a> that encapsulates the various individual recourse methods we have chosen to use in our experiments. We then introduce the notion of a hidden external cost in algorithmic recourse and extend the existing framework to explicitly address this cost in the counterfactual search objective.</p>
<section id="sec-method-general" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="sec-method-general"><span class="header-section-number">3.1</span> From individual recourse …</h2>
<p>We have chosen to focus on gradient-based counterfactual search for two reasons: firstly, they can be seen as direct descendants of our baseline method - Wachter; secondly, gradient-based search is particularly well-suited for differentiable black-box models like deep neural networks, which we focus on in this work. In particular, we include include the following generators in our simulation experiments below: <strong>REVISE</strong> <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span>, <strong>CLUE</strong> <span class="citation" data-cites="antoran2020getting"><a href="#ref-antoran2020getting" role="doc-biblioref">[9]</a></span>, <strong>DiCE</strong> <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> and a greedy approach that relies on probabilistic models <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>. Our motivation for including these different generators in our analysis, is that they all offer slightly different approaches to generate meaningful counterfactuals for differentiable black-box models. We hypothesize that generating more <strong>meaningful</strong> counterfactuals should mitigate the endogenous dynamics illustrated in <a href="#fig-poc">Figure&nbsp;1</a> in <a href="#sec-intro">Section&nbsp;1</a>. This intuition stems from the underlying idea that more meaningful counterfactuals are generated by the same or at least a very similar data generating process as the training data. All else equal, counterfactuals that fulfill this basic requirement should be less prone to trigger domain and model shifts.</p>
<p>As we will see next, all of them can be described by the following generalized form of <a href="#eq-solution">Equation&nbsp;2</a>:</p>
<p><span id="eq-general"><span class="math display">\[
\begin{aligned}
\mathbf{s}^\prime &amp;= \arg \min_{\mathbf{s}^\prime \in \mathcal{S}} \left\{ \sum_{k=1}^{K} {\ell(M(f(s_k^\prime)),y^*)}+ \lambda {h(f(s_k^\prime)) }  \right\}
\end{aligned}
\tag{3}\]</span></span></p>
<p>Here <span class="math inline">\(\mathbf{s}^\prime=\left\{s_k^\prime\right\}_K\)</span> is the stacked <span class="math inline">\(K\)</span>-dimensional array of counterfactual states and <span class="math inline">\(f: \mathcal{S} \mapsto \mathcal{X}\)</span> maps from the counterfactual state space to the feature space. In Wachter, the state space is the feature space: <span class="math inline">\(f\)</span> is just the identity function and the number of counterfactuals <span class="math inline">\(K\)</span> is equal to one. Both REVISE and CLUE search counterfactuals in some latent embedding <span class="math inline">\(S \subset \mathcal{S}\)</span> instead of the feature space directly. The latent embedding is learned by a separate generative model that is tasked with learning the data generating process (DGP) of <span class="math inline">\(X\)</span>. In this case <span class="math inline">\(f\)</span> in <a href="#eq-general">Equation&nbsp;3</a> corresponds to the decoder part of the generative model, in other words the function that maps back from the latent embedding to the feature space. Provided the generative model is well-specified, traversing the latent embedding typically results in realistic and plausible counterfactuals, because they are implicitly generated by the (learned) DGP <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span>.</p>
<p>CLUE distinguishes itself from REVISE and other counterfactual generators in that it aims to minimize the predictive uncertainty of the model in question, <span class="math inline">\(M\)</span>. To quantify predictive uncertainty the authors rely on entropy estimates for probabilistic models. The approach proposed by <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>, which we shall refer to as <strong>Greedy</strong>, also works with the subclass of models <span class="math inline">\(\tilde{\mathcal{M}}\subset\mathcal{M}\)</span> that can produce predictive uncertainty estimates. The authors show that in this setting the cost function <span class="math inline">\(h(\cdot)\)</span> in <a href="#eq-general">Equation&nbsp;3</a> is redundant and meaningful counterfactuals can be generated in a fast and efficient manner through a modified Jacobian-based Saliency Map Attack (JSMA). Schut et al. <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span> also show that by maximizing the predicted probability of <span class="math inline">\(x^\prime\)</span> being assigned to target class <span class="math inline">\(y^*\)</span> we also implicitly minimize predictive entropy - as in CLUE. In that sense, CLUE can be seen as equivalent to REVISE in the Bayesian context and we shall therefore refer to both approaches collectively as <strong>Latent Space</strong> generators<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<p>Finally, DiCE <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> distinguishes itself from all other generators considered here in that it aims to generate a diverse set of <span class="math inline">\(K&gt;1\)</span> counterfactuals. Wachter et al. <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span> show that diverse outcomes can in principal be achieved simply rerunning counterfactual search multiple times using stochastic gradient descent (or by randomly initializing the counterfactual). In <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> diversity is explicitly proxied via Determinantal Point Processes (DDP): the authors simply introduce DDP as a component of the cost function <span class="math inline">\(h(\mathbf{s}^\prime)\)</span> and therebt produce counterfactuals <span class="math inline">\(s_1, ... , s_K\)</span> that look as different from each other as possible. The implementation of DiCE in the our library of choice - <code>CounterfactualExplanations.jl</code> - uses that exact approach. It is worth noting that for <span class="math inline">\(k=1\)</span>, DiCE reduces to Wachter since the DDP is constant and therefore does not affect the objective function <a href="#eq-general">Equation&nbsp;3</a>.</p>
</section>
<section id="towards-collective-recourse" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="towards-collective-recourse"><span class="header-section-number">3.2</span> … towards collective recourse</h2>
<p>All of the different approaches introduced above tackle the problem of Algorithmic Recourse from the perspective of one single individual<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. To explicitly address the issue that individual recourse may affect the outcome and prospect of other individuals, we propose to extend <a href="#eq-general">Equation&nbsp;3</a> as follows:</p>
<p><span id="eq-collective"><span class="math display">\[
\begin{aligned}
\mathbf{s}^\prime &amp;= \arg \min_{\mathbf{s}^\prime \in \mathcal{S}}  \sum_{k=1}^{K} {\ell(M(f(s_k^\prime)),y^*)} \\ &amp;+ \lambda_1 {h(f(s_k^\prime)) } + \lambda_2 {g(f(s_k^\prime))}  
\end{aligned}
\tag{4}\]</span></span></p>
<p>Here <span class="math inline">\(h(f(s_k^\prime))\)</span> denotes the proxy for private costs faced by the individual as before and <span class="math inline">\(\lambda_1\)</span> governs to what extent that private cost ought to be penalized. The newly introduced term <span class="math inline">\(g(f(s_k^\prime))\)</span> is meant to capture and address external costs incurred by the collective of individuals in response to changes in <span class="math inline">\(\mathbf{s}^\prime\)</span>. The underlying concept of private and external costs is borrowed from Economics and well-established in that field: when the decisions or actions by some individual market participant generate external costs, then the market is said to suffer from negative externalities and considered inefficient <span class="citation" data-cites="pindyck2014microeconomics"><a href="#ref-pindyck2014microeconomics" role="doc-biblioref">[24]</a></span>. We think that this concept describes the endogenous dynamics of algorithmic recourse oberserved here very well. As with individual recourse, the exact choice of <span class="math inline">\(g(\cdot)\)</span> is not obvious, nor do we intend to provide a definite answer in this work, if such even exists. That being said, we do propose a few potential mitigation strategies in <a href="#sec-empirical-2-mitigate">Section&nbsp;7</a>.</p>
</section>
</section>
<section id="sec-method-2" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> Modeling Endogenous Macrodynamics in Algorithmic Recourse</h1>
<p>In the following we describe the framework we propose for modeling and analysing endogenous macrodynamics in Algorithmic Recourse. We first describe the basic simulations that were generated to produce the findings in this work and also constitute the core of <code>AlgorithmicRecourseDynamics.jl</code> - the Julia package we introduced earlier. The remainder of this section then introduces various evaluation metrics that can be used to benchmark different counterfactual generators with respect to how they perform in the dynamic setting.</p>
<section id="sec-method-2-experiment" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="sec-method-2-experiment"><span class="header-section-number">4.1</span> Simulations</h2>
<p>The dynamics illustrated in <a href="#fig-poc">Figure&nbsp;1</a> in <a href="#sec-intro">Section&nbsp;1</a> were generated through a simple experiment that aims to simulate the process of Algorithmic Recourse in practice. We begin in the static setting at time time <span class="math inline">\(t=0\)</span>: given some classifier <span class="math inline">\(M\)</span> that was pre-trained on data <span class="math inline">\(\mathcal{D}=\mathcal{D}_0 \cup \mathcal{D}_1\)</span> we generate recourse for a random batch of <span class="math inline">\(B\)</span> individuals in the non-target class (<span class="math inline">\(\mathcal{D}_0\)</span>). Note that we focus our attention on classification problems, since classification poses the most common practical use-case for Algorithmic Recourse. In order to simulate the dynamic process, we suppose that the model <span class="math inline">\(M\)</span> is retrained following the actual implementation of recourse in time <span class="math inline">\(t=0\)</span>. Following the update to the model, we assume that at time <span class="math inline">\(t=1\)</span> recourse is generated for yet another random subset of individuals in the non-target class. This process is repeated for a number of time periods <span class="math inline">\(T\)</span>. To get a clean read on endogenous dynamics we keep the total population of samples closed: we allow existing samples to move from factual to counterfactual states, but do not allow any entirely new samples to enter the population. The experimental setup is summarized in Algorithm <span class="math inline">\(\ref{algo-experiment}\)</span></p>
<p>A noteworthy practical consideration is the choice of <span class="math inline">\(T\)</span> and <span class="math inline">\(B\)</span>. The higher these values, the more factual instances undergo recourse throughout the entire experiment. Of course, this is likely to lead to more pronounced domain and model shifts by time <span class="math inline">\(T\)</span>. At the same time, it is generally improbable that a very large part of the population would request an explanation of the algorithm’s decisions. In our experiments, we choose the values such that <span class="math inline">\(T \cdot B\)</span> corresponds to the application of recourse on <span class="math inline">\(\approx50\%\)</span> of the negative instances from the initial dataset. As we collect data at each time <span class="math inline">\(t\)</span>, we can also verify the impact of recourse when it is implemented for a smaller number of individuals.</p>
<p>Algorithm <span class="math inline">\(\ref{algo-experiment}\)</span> summarizes the proposed simulation experiment for a given dataset <span class="math inline">\(\mathcal{D}\)</span>, model <span class="math inline">\(M\)</span> and generator <span class="math inline">\(G\)</span>, but naturally we are interested in comparing simulation outcomes for different sources of data, models and generators. The framework we have built facilitates this, making use of multi-threading in order to speed up computations. Holding the initial model and dataset constant the experiments are run for all generators, since our primary concern is to benchmark different recourse methods. To ensure that each generator is faced with the exact same initial conditions in each round <span class="math inline">\(t\)</span>, the candidate batch of individuals from the non-target class is randomly drawn from the intersection of all individuals in the non-target class across all experiments <span class="math inline">\(\left\{\textsc{Experiment}(M,\mathcal{D},G)\right\}_{j=1}^J\)</span> where <span class="math inline">\(J\)</span> is the total number of generators.</p>
</section>
<section id="sec-method-2-metrics" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="sec-method-2-metrics"><span class="header-section-number">4.2</span> Evaluation Metrics</h2>
<p>We formulate two desiderata for the set of metrics used to measure domain and model shifts induced by recourse. First, the metrics should be applicable regardless of the dataset or classification technique so that they allow for the meaningful comparison of the generators in various scenarios. As the knowledge of the underlying probability distribution is rarely available, the metrics should be empirical and non-parametric. This further ensures that we can also measure large datasets by sampling from the available data. Moreover, while our study was conducted in a two-class classification setting, our choice of metrics should remain applicable in the future research on multi- class recourse problems. Second, the set of metrics should allow to capture various aspects of the previously mentioned magnitude, path, and tempo of changes while remaining as small as possible.</p>
<section id="domain-shifts" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="domain-shifts"><span class="header-section-number">4.2.1</span> Domain Shifts</h3>
<p>To quantify the magnitude of domain shifts we rely on an unbiased estimate of the squared population <strong>Maximum Mean Discrepancy (MMD)</strong> given as:</p>
<p><span id="eq-mmd"><span class="math display">\[
\begin{aligned}
MMD^2_u[F,{X}^\prime,\tilde{X}^\prime] &amp;= \frac{1}{m(m-1)}\sum_{i=1}^m\sum_{j\neq i}^m k(x_i,x_j) \\ &amp;+ \frac{1}{n(n-1)}\sum_{i=1}^n\sum_{j\neq i}^n k(\tilde{x}_i,\tilde{x}_j) \\ &amp;- \frac{2}{mn}\sum_{i=1}^m\sum_{j=1}^n k(x_i,\tilde{x}_j)
\end{aligned}
\tag{5}\]</span></span></p>
<p>where <span class="math inline">\(\mathcal{F}\)</span> is a unit ball in a Reproducing Kernel Hilbert Space <span class="math inline">\(\mathcal{H}\)</span> <span class="citation" data-cites="berlinet2011reproducing"><a href="#ref-berlinet2011reproducing" role="doc-biblioref">[25]</a></span>, and <span class="math inline">\(X\)</span>, <span class="math inline">\(\tilde{X}\)</span> represent independent and identically distributed samples drawn from probability distributions <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{\tilde{X}}\)</span> respectively <span class="citation" data-cites="gretton2012kernel"><a href="#ref-gretton2012kernel" role="doc-biblioref">[26]</a></span>. MMD is a measure of the distance between the kernel mean embeddings of <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{\tilde{X}}\)</span> in RKHS <span class="math inline">\(\mathcal{H}\)</span>. An important consideration is the choice of the kernel function <span class="math inline">\(k(\cdot,\cdot)\)</span>. In our implementation we make use of Gaussian kernel with a constant length-scale parameter of <span class="math inline">\(0.5\)</span>. As the Gaussian kernel captures all moments of distributions <span class="math inline">\(\mathcal{X}\)</span> and <span class="math inline">\(\mathcal{\tilde{X}}\)</span>, we have that <span class="math inline">\(MMD_u^2[F,X,\tilde{X}]=0\)</span> if and only if <span class="math inline">\(X=\tilde{X}\)</span>.</p>
<p>The evaluation metric in <a href="#eq-mmd">Equation&nbsp;5</a> is computed after every round <span class="math inline">\(t=1,...,T\)</span> of the experiment. To assess the statistical significance of the observed shifts under the null hypothesis that samples <span class="math inline">\(X\)</span> and <span class="math inline">\(\tilde{X}\)</span> were drawn from the same probability distribution, we follow <span class="citation" data-cites="arcones1992bootstrap"><a href="#ref-arcones1992bootstrap" role="doc-biblioref">[27]</a></span>. To that end, we combine the two samples and generate a large number of permutations of <span class="math inline">\(X + \tilde{X}\)</span>. Then, we split the permuted data into two new samples <span class="math inline">\(X^\prime\)</span> and <span class="math inline">\(\tilde{X}^\prime\)</span> having the same size as the original samples. Then under the null hypothesis we should have that <span class="math inline">\(MMD_u^2[F,X^\prime,\tilde{X}^\prime]\)</span> be approximately equal to <span class="math inline">\(MMD_u^2[F,X,\tilde{X}]\)</span>. The corresponding <span class="math inline">\(p\)</span>-value can then be calculated by counting how these two quantities are not equal.</p>
<p>We calculate the MMD for both classes individually based on the ground truth labels, i.e.&nbsp;the labels that samples were assigned in time <span class="math inline">\(t=0\)</span>. Throughout our experiments, we generally do not expect the distribution of the negative class to change over time – application of recourse reduces the size of this class, but since individuals are sampled uniformly the distribution should remain unaffected. Conversely, unless a recourse generator can perfectly replicate the original probability distribution, we expect the MMD of the positive class to increase. Thus, when discussing MMD, we generally mean the shift in the distribution of the positive class.</p>
</section>
<section id="model-shifts" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="model-shifts"><span class="header-section-number">4.2.2</span> Model Shifts</h3>
<p>As our baseline for quantifying model shifts we measure perturbations to the model parameters at each point in time <span class="math inline">\(t\)</span> following <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. We define <span class="math inline">\(\Delta=||\theta_{t+1}-\theta_{t}||^2\)</span>, that is the euclidean distance between the vectors of parameters before and after retraining the model <span class="math inline">\(M\)</span>. We shall refer to this baseline metric simply as <strong>Perturbations</strong>.</p>
<p>We extend the metric in <a href="#eq-mmd">Equation&nbsp;5</a> for the purpose of quantifying model shifts. Specifically, we introduce <strong>Predicted Probability MMD (PP MMD)</strong>: instead of applying <a href="#eq-mmd">Equation&nbsp;5</a> to features directly, we apply it to the predicted probabilities assigned to a set of samples by the model <span class="math inline">\(M\)</span>. If the model shifts, the probabilities assigned to each sample will change; again, this metric will equal 0 only if the two classifiers are the same. We compute PP MMD in two ways: firstly, we compute it over samples drawn uniformly from the dataset, and, secondly, we compute it over points spanning a meshgrid over a subspace of the entire feature space. For the latter approach we bound the subspace by the extrema of each feature. While this approach is theoretically more robust, unfortunately, it suffers from the curse of dimensionality, since it becomes increasingly difficult to select enough points to overcome noise as the dimension <span class="math inline">\(D\)</span> grows.</p>
<p>As an alternative to PP MMD we use a pseudo-distance for the <strong>Disagreement Coefficient</strong> (Disagreement). This metric was introduced in <span class="citation" data-cites="hanneke2007bound"><a href="#ref-hanneke2007bound" role="doc-biblioref">[28]</a></span> and estimates <span class="math inline">\(p(M(x) \neq M^\prime(x))\)</span>, that is the probability that two classifiers do not agree on the predicted outcome for a randomly chosen sample. Thus, it is not relevant whether the classification is correct according to the ground truth, but only whether the sample lies on the same side of the two respective decision boundaries. In our context, this metric quantifies the overlap between the initial model (trained before the application of recourse) and the updated model. A Disagreement Coefficient unequal to zero is indicative of a model shift. The opposite is not true: even if the Disagreement Coefficient is equal to zero a model shift may still have occured. This is one reason for why PP MMD is our our preferred metric.</p>
<p>We further introduce <strong>Decisiveness</strong> as a metric that quantifies the likelihood that a model assigns a high probability to its classification of any given sample. We define the metric simply as <span class="math inline">\({1\over{N}}\sum_{i=0}^N(\sigma(M(x)) − 0.5)^2\)</span> where <span class="math inline">\(M(x)\)</span> are predicted logits from a binary classifier and <span class="math inline">\(\sigma\)</span> denotes the sigmoid function. This metric provides an unbiased estimate of the binary classifier’s tendency to produce high-confidence predictions in either one of the two classes. Although the exact values for this metric are not important for our study, they can be used to detect model shifts. If decisiveness changes over time, then this is indicative of the decision boundary moves towards either one of the two classes.</p>
<p>Finally, we also take a look at the out-of-sample <strong>Performance</strong> of our models. To this end, we compute their F-score on a test sample that we leave untouched throughout the experiment.</p>
</section>
</section>
</section>
<section id="sec-empirical" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> Experiment Setup</h1>
<p>This section presents the exact ingredients and parameter choices describing the simulation experiments we ran to produce the findings presented in the next section (<a href="#sec-empirical-2">Section&nbsp;6</a>). For convenience, we use Algorithm <span class="math inline">\(\ref{algo-experiment}\)</span> as a template to guide us through this section. A few high-level details upfront: each experiment is run for a total of <span class="math inline">\(T=50\)</span> rounds, where in each round we provide recourse to five percent of all individuals in the non-target class, so <span class="math inline">\(B_t=0.05 * N_t^{\mathcal{D}_0}\)</span><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>. All classifiers and generative models are retrained for 10 epochs in each round <span class="math inline">\(t\)</span> of the experiment. Rather than retraining models from scratch, we initialize all parameters at their previous levels (<span class="math inline">\(t-1\)</span>) and compute backpropagate for 10 epochs using the new training data as inputs into the existing model. Evaluation metrics are computed and stored every 10 rounds. To account for noise each individual experiment is repeat five times.</p>
<section id="sec-empirical-classifiers" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="sec-empirical-classifiers"><span class="header-section-number">5.1</span> <span class="math inline">\(M\)</span> – Classifiers and Generative Models</h2>
<p>For each dataset and generator we look at three different types of classifiers all of them built and trained using <code>Flux.jl</code> <span class="citation" data-cites="innes2018fashionable"><a href="#ref-innes2018fashionable" role="doc-biblioref">[29]</a></span>: firstly, a simple linear classifier - <strong>Logistic Regression</strong> - implemented as single linear layer with sigmoid activation; secondly, a multilayer perceptron (<strong>MLP</strong>); and finally, a <strong>Deep Ensemble</strong> composed of five MLPs following <span class="citation" data-cites="lakshminarayanan2016simple"><a href="#ref-lakshminarayanan2016simple" role="doc-biblioref">[30]</a></span> that serves as our only probabilistic classifier. We have chosen to work with deep ensembles both for their simplicity and effectiveness at modelling predictive uncertainty. They are also the model of choice in <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>. The actual neural network architectures are kept simple (<a href="#tbl-mlp">Table&nbsp;1 (a)</a>), since we are only marginally concerned with achieving good initial classifier performance. For the real-world datasets we using mini-batch training and dropout regularization.</p>
<p>The Latent Space generators rely on separate generative models. Following the authors of both REVISE and CLUE we use Variational Autoencoders (<strong>VAE</strong>) for this purpose. As with the classifiers, we deliberately choose to work with fairly simple architectures (<a href="#tbl-vae">Table&nbsp;1 (b)</a>). More expressive generative models generally also lead to more meaningful counterfactuals produced by Latent Space generators. But in our view this should simply be considered as a vulnerability of counterfactual generators that rely on surrogate models to learn what realistic representations of the underlying data.</p>
<div id="tbl-panel" class="tbl-parent quarto-layout-panel anchored">
<div class="panel-caption table-caption">
<p>Table 1: Model Architectures</p>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-mlp" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-panel" style="flex-basis: 100.0%;justify-content: center;">
<table class="table">
<caption>(a) MLP</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Hidden Dim.</th>
<th style="text-align: left;">Hidden Layers</th>
<th style="text-align: left;">Batch</th>
<th style="text-align: left;">Dropout</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Synthetic</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">-</td>
<td style="text-align: left;">-</td>
</tr>
<tr class="even">
<td style="text-align: left;">Real-World</td>
<td style="text-align: left;">32</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">50</td>
<td style="text-align: left;">0.25</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="quarto-layout-row quarto-layout-valign-top">
<div id="tbl-vae" class="quarto-layout-cell quarto-layout-cell-subref anchored" data-ref-parent="tbl-panel" style="flex-basis: 100.0%;justify-content: center;">
<table class="table">
<caption>(b) Variational Autoencoder</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Hidden Dim.</th>
<th style="text-align: left;">Epochs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Synthetic</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">100</td>
</tr>
<tr class="even">
<td style="text-align: left;">Real-World</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">250</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="sec-empirical-data" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="sec-empirical-data"><span class="header-section-number">5.2</span> <span class="math inline">\(\mathcal{D}\)</span> – Data</h2>
<p>We have chosen to work with both synthetic and real-world datasets. Using synthetic data allows us to impose distributional properties that may affect the resulting recourse dynamics. Following <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>, we generate synthetic data in <span class="math inline">\(\mathbb{R}^2\)</span> to also allow for a visual interpretation of the results. Real-world data is used in order to assess if endogenous dynamics also occur in higher-dimensional settings.</p>
<section id="synthetic-data" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="synthetic-data"><span class="header-section-number">5.2.1</span> Synthetic data</h3>
<p>We use four synthetic binary classification datasets consisting of 1000 samples each. The datasets are presented in <a href="#fig-synthetic-data">Figure&nbsp;2</a> (see also Appendix A for a formal description). Samples from the negative class are marked in blue while samples of the positive class are marked in orange.</p>
<div id="fig-synthetic-data" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/synthetic_data.png" data-fig.pos="h" style="width:8cm;height:2cm" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2: Synthetic classification datasets used in our experiments.</figcaption><p></p>
</figure>
</div>
<p>Ex-ante we expect to see that by construction Wachter will create a new cluster of counterfactual instances in the proximity of the initial decision boundary. Thus, the choice of a black-box model may have an impact on the paths of the recourse. For generators that use latent space search (REVISE <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span>, CLUE <span class="citation" data-cites="antoran2020getting"><a href="#ref-antoran2020getting" role="doc-biblioref">[9]</a></span>) or rely on (and have access to) probabilistic models (CLUE <span class="citation" data-cites="antoran2020getting"><a href="#ref-antoran2020getting" role="doc-biblioref">[9]</a></span>, Greedy <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>) we expect that counterfactuals will end up in regions of the target domain that are densely populated by training samples. Of course, this is expectation hinges on how effective said probabilistic models are at capturing predictive uncertainty. Finally, we expect to see the counterfactuals generated by DiCE to be uniformly spread around the feature space inside the target class<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. In summary, we expect that the endogenous shifts induced by Wachter outsize those induced by all other generators, since Wachter is the only approach that is not concered with generating what we have defined as meaningful counterfactuals.</p>
</section>
<section id="real-world-data" class="level3" data-number="5.2.2">
<h3 data-number="5.2.2" class="anchored" data-anchor-id="real-world-data"><span class="header-section-number">5.2.2</span> Real-world data</h3>
<p>We use three different real-world datasets from the Finance and Economics domain, all of which are tabular and can be used for binary classification. Firstly, we use the <strong>Give Me Some Credit</strong> dataset which was open-sourced on Kaggle for the task to predict whether a borrower is likely to experience financial difficulties in the next two years <span class="citation" data-cites="gmsc_data"><a href="#ref-gmsc_data" role="doc-biblioref">[31]</a></span>. Originally consisting of 250,000 instances with 11 numerical attributes. Secondly, we use the <strong>UCI defaultCredit</strong> dataset <span class="citation" data-cites="yeh2009comparisons"><a href="#ref-yeh2009comparisons" role="doc-biblioref">[32]</a></span>, a benchmark dataset that can be used to train binary classifiers to predict the binary outcome variable, whether credit card clients default on their payment. In its raw form it consists of 23 explanatory variables - 4 categorical features relating to demographic attributes<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> and 19 continuous features largely relating to individuals’ payment histories and amount of credit outstanding. Both of these datasets have been used in the literature on Algorithmic Recourse before (see for example <span class="citation" data-cites="pawelczyk2021carla"><a href="#ref-pawelczyk2021carla" role="doc-biblioref">[3]</a></span>, <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span> and <span class="citation" data-cites="ustun2019actionable"><a href="#ref-ustun2019actionable" role="doc-biblioref">[12]</a></span>), presumably because they constitute real-world classification tasks involving individuals that compete for access to credit.</p>
<p>As a third dataset we include the <strong>California Housing</strong> dataset derived from the 1990 U.S. census and sourced through scikit-learn <span class="citation" data-cites="pedregosa2011scikit"><a href="#ref-pace1997sparse" role="doc-biblioref">[34]</a></span>. It consists of 8 continuous features that can be used to predict the median house price for California districts. The continuous outcome variable is binarized as <span class="math inline">\(\tilde{y}=\mathbb{I}_{y&gt;\text{median}(Y)}\)</span> indicating whether or not the median house price of a given district is above or below the median of all districts. While we have not seen this dataset used in the previous literature on AR, others have used the Boston Housing dataset in a similar fashion (see for example <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>). While we initially also conducted experiments on that dataset, we eventually discarded this dataset, since it has been found to suffer from an ethical problem <span class="citation" data-cites="carlisle2019racist"><a href="#ref-carlisle2019racist" role="doc-biblioref">[35]</a></span>.</p>
<p>Since the simulations involve generating counterfactuals for a significant proportion of the entire sample of individuals, we have randomly undersampled each dataset to yield balanced subsamples consisting of 10,000 individuals each. We have also standardized all explanatory features since our chosen classifiers are sensetive to scale.</p>
</section>
</section>
<section id="g-generators" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="g-generators"><span class="header-section-number">5.3</span> <span class="math inline">\(G\)</span> – Generators</h2>
<p>All generators introduced earlier are included in the experiments: Wachter <span class="citation" data-cites="wachter2017counterfactual"><a href="#ref-wachter2017counterfactual" role="doc-biblioref">[4]</a></span>, REVISE <span class="citation" data-cites="joshi2019towards"><a href="#ref-joshi2019towards" role="doc-biblioref">[7]</a></span>, CLUE <span class="citation" data-cites="antoran2020getting"><a href="#ref-antoran2020getting" role="doc-biblioref">[9]</a></span>, DiCE <span class="citation" data-cites="mothilal2020explaining"><a href="#ref-mothilal2020explaining" role="doc-biblioref">[8]</a></span> and Greedy <span class="citation" data-cites="schut2021generating"><a href="#ref-schut2021generating" role="doc-biblioref">[6]</a></span>. In addition, we introduce two new generators in <a href="#sec-empirical-2-mitigate">Section&nbsp;7</a> that directly address the issue of endogenous domain and model shifts. We also test to what extent it may be beneficial to combine ideas underlying the various generators.</p>
</section>
</section>
<section id="sec-empirical-2" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> Experiments</h1>
<p>Below we first present our main findings with respect to the presence of endogenous macrodynamics in Algorithmic Recourse. We then go on to introduce and test a number of potential mitigation strategies.</p>
<section id="endogenous-macrodynamics" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="endogenous-macrodynamics"><span class="header-section-number">6.1</span> Endogenous Macrodynamics</h2>
<p>In light of the huge number of experiments we have conducted, we shall start this section off with a few high-level observations. Across all datasets (synthetic and real), classifiers and counterfactual generators we observe either most or all of the following dynamics at varying degrees:</p>
<ul>
<li>Statistically significant domain and model shift as measured by MMD.</li>
<li>A deterioration in out-of-sample model performance as measured by the F-Score evaluated on a test sample. In many cases this drop in performance is substantial.</li>
<li>Significant perturbations to the model parameters as well as an increase in the model’s decisiveness.</li>
<li>Disagreement between the original and retrained model, in some cases large.</li>
</ul>
<p>There is also some clear heterogeneity across the results:</p>
<ul>
<li>The observed, adverse dynamics are generally speaking of the highest magnitude for the simple linear classifier. Differences in results for the MLP and Deep Ensemble are mostly negligible.</li>
<li>The reduction in model performance appears to be most severe when classes are not perfectly separable.</li>
<li>With the exception of the Greedy generator, all other generators generally perform somewhat better than Wachter overall as expected.</li>
</ul>
<p>Granular tables and visualizations summarizing all of our experimental results are published in the supplementary appendix. Here we will zoom in on illustrative examples that nicely reflect some of the broader patterns we have observed and listed above. <a href="#fig-syn">Figure&nbsp;3</a> presents a small subset of our results for the synthetic dataset with overlapping classes. It shows the resulting values for some of our evaluation metrics at the end of the experiment, so after all <span class="math inline">\(T=50\)</span> rounds, along with error bars indicating the variation across folds. The top row shows the estimated domain shifts. While it is not straight-forward to interpret the exact magnitude of MMD, we can see clearly that the values are different from zero and there is essentially no variation across our five folds. With respect to the domain shifts, the Greedy generator actually induces the smallest shifts. In general, we have observed the opposite. The second row shows the estimated model shifts, where here we have used the meshgrid approach explained earlier. As with the domain shifts, the observed values are clearly different from zero and variation across folds is once again small. In this case, the results for this particular dataset very much reflect the broader patterns we have observed: Latent Space generators induce the smallest shifts, followed by DiCE, then Wachter and finally Greedy. The same broad pattern also emerges in the bottom row: we observe the smallest deterioration in model performance for Latent Space generators, albeit still a reduction in the F-Score of around 5 percentage points on average.</p>
<div id="fig-syn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/synthetic_results.png" data-fig.pos="h" style="width:9cm;height:9cm" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 3: Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a meshgrid of points. Error bars indicate the standard deviation across folds.</figcaption><p></p>
</figure>
</div>
<p>Turning to the real-world data next …</p>
<div id="fig-real" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/placeholder.png" data-fig.pos="h" style="width:9cm;height:9cm" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 4: PLACEHOLDER: Results for real-world as table.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="sec-empirical-2-mitigate" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> Potential Mitigation Strategies</h1>
<p>In the following we explore several ideas for strategies that may help to mitigate those types of endogenous recourse dynamics we observed in the previous subsection. All of them essentially boil down to one simple principle: to avoid substantial domain and model shifts, the generated counterfactuals should comply as much as possible with the true data generating process. This principle is really at the core of Latent Space generators, and hence it is not surprising that we have found these types of generators to perform comparably well in the previous subsection. But as we have mentioned earlier, generators that rely on separate generative models carry an additional computational cost and - perhaps more importantly - their performance hinges on the performance of said generative models. Fortunately, it turns out that we can use a number of other, much simpler strategies, which we will discuss now.</p>
<section id="more-conservative-decision-thresholds" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="more-conservative-decision-thresholds"><span class="header-section-number">7.1</span> More Conservative Decision Thresholds</h2>
<p>The most obvious and trivial mitigation strategy is to simply choose a higher decision threshold <span class="math inline">\(\gamma\)</span>. Under <span class="math inline">\(\gamma=0.5\)</span>, counterfactuals will end up near the decision boundary by construction. Since this is the region of maximal aleotoric uncertainty, the classifier is bound to be thrown off. By simply setting a more conservative decision threshold, we can avoid this issue to some extent. A potential drawback of this approach is that a classifier with high decisiveness may classify samples with high confidence even far away from the training data.</p>
</section>
<section id="classifier-preserving-roar" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="classifier-preserving-roar"><span class="header-section-number">7.2</span> Classifier Preserving ROAR</h2>
<p>Another potential strategy draws inspiration from ROAR <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>: to preserve the classifier, we propose to simply explicitly penalize the loss it incurs when evaluated on the counterfactual <span class="math inline">\(x^\prime\)</span> at given parameter values. Recall that <span class="math inline">\(g(\cdot)\)</span> denotes what we had defined as the external cost in <a href="#eq-collective">Equation&nbsp;4</a>. Then formally we let</p>
<p><span id="eq-clap"><span class="math display">\[
\begin{aligned}
g(f(s_k^\prime)) = l(M(f(s_k^\prime)),y^\prime)
\end{aligned}
\tag{6}\]</span></span></p>
<p>for each counterfactual <span class="math inline">\(k\)</span> where <span class="math inline">\(l\)</span> denotes the loss function used to train <span class="math inline">\(M\)</span>. This approach, which we shall refer to as <strong>ClapROAR</strong>, is based on the intuition that (endogenous) model shifts will be triggered by counterfactuals that increase classifier loss. It is closely linked to the idea of choosing higher decision threshold, but likely better at avoiding the potential pitfalls associated with highly decisive classifiers. It also makes the private vs.&nbsp;external cost trade-off more explicit and hence manageable.</p>
</section>
<section id="gravitational-counterfactual-explanations" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="gravitational-counterfactual-explanations"><span class="header-section-number">7.3</span> Gravitational Counterfactual Explanations</h2>
<p>Yet another strategy simply extends Wachter as follows: instead of only penalizing the distance of the individuals’ counterfactual to its factual, we propose penalizing its distance to some sensible point in the target domain, for example the sample average: <span class="math inline">\(\bar{x}\)</span>:</p>
<p><span id="eq-clap"><span class="math display">\[
\begin{aligned}
g(f(s_k^\prime)) = \text{dist}(f(s_k^\prime),\bar{x})
\end{aligned}
\tag{7}\]</span></span></p>
<p>Once again we can putting this in the context of <a href="#eq-collective">Equation&nbsp;4</a>, the former penalty can be thought of here as the private cost incurred by the individual, while the latter reflects the external cost incurred by other individuals. Higher choices of <span class="math inline">\(\lambda_2\)</span> relative to <span class="math inline">\(\lambda_1\)</span> will lead counterfactuals to gravitate towards the specified point <span class="math inline">\(\bar{x}\)</span> in the target domain. In the remainder of this paper we will therefore refer to this approach as <strong>Gravitational</strong> generator, when we investigate its potential usefulness for mitigating endongenous macrodynamics<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a>.</p>
<p><a href="#fig-mitigation">Figure&nbsp;5</a> hows an illustrative example that demonstrates the differences in counterfactual outcomes when using the various mitigation strategies compared to the baseline approach, that is Wachter with <span class="math inline">\(\gamma=0.5\)</span>: choosing a higher decision threshold pushes the counterfactual a little further into the target domain; this effect is even stronger for ClapROAR; finally, using the Gravitational generator the counterfactual ends up all the way inside the target domain in the neighbourhood of <span class="math inline">\(\bar{x}\)</span><a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>.</p>
<div id="fig-mitigation" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/mitigation.png" class="img-fluid figure-img" data-fig.pos="h" style="width:45.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5: Illustrative example demonstrating the properties of the various mitigation strategies.</figcaption><p></p>
</figure>
</div>
<p>Our findings indicate that all three mitigation strategies are at least at par with Latent Space generators with respect to their effectiveness at mitigating domain and model shifts. <a href="#fig-mitigate-results">Figure&nbsp;6</a> presents a subset of the evaluation metrics for our synthetic data with overlapping classes. The top row in <a href="#fig-mitigate-results">Figure&nbsp;6</a> indicates that while domain shifts are of roughly the same magnitude for both Wachter and Latent Space generators, our proposed strategies effectively mitigate these shifts. ClapROAR appears to be particularly effective, which is positively surprising, since it is designed to explicitly address model shifts, not domain shifts. As evident from the middle row in <a href="#fig-mitigate-results">Figure&nbsp;6</a> model shifts can also be reduced: for the deep ensemble Latent Space search yields results that are at par with the mitigation strategies, while for both the simple MLP and logistic regression our simple strategies are actually more effective. The same overall pattern can be observed for out-of-sample model performance. With respect to the other synthetic datasets we found the following: for the Moons dataset the emerging patterns are largely the same, but the estimated model shifts are insignificant as noted earlier; the same holds for the Circles dataset, but there is no significant reduction in model performance for our neural networks; in the case of linearly separable data we find the Gravitational generator to be most effective at mitigating shifts.</p>
<div id="fig-mitigate-results" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/mitigation_synthetic_results.png" class="img-fluid figure-img" data-fig.pos="h" style="width:45.0%"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 6: The differences in counterfactual outcomes when using the various mitigation strategies compared to the baseline approach, that is Wachter with <span class="math inline">\(\gamma=0.5\)</span>. Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a meshgrid of points. Error bars indicate the standard deviation across folds.</figcaption><p></p>
</figure>
</div>
<p>An interesting finding is also that the proposed strategies can have a complementary effect when used in combination with Latent Space generators. In experiments we conducted on the synthetic data, the benefits of Latent Space generators were exacerbated further when using a more conservative threshold or combining it with the penalties underlying Gravitational and ClapROAR. A snapshot of the results is shown in <a href="#fig-mitigate-latent-results">Figure&nbsp;7</a>.</p>
<div id="fig-mitigate-latent-results" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="www/mitigation_synthetic_latent_results.png" data-fig.pos="h" style="width:9cm;height:9cm" class="figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 7: Combinining various mitigation strategies with Latent Space search. Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a meshgrid of points. Error bars indicate the standard deviation across folds.</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="sec-discussion" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> Discussion</h1>
<p>Our results in <a href="#sec-empirical-2">Section&nbsp;6</a> indicate that state-of-the-art approaches to Algorithmic Recourse induce substantial domain and model shift, if implemented at scale in practice. These induced shifts can and should be considered as an (expected) external cost of individual recourse. While they do not affect the individual directly as long as we look at the individual in isolation, they can been seen to affect the broader group of stakeholders in automated data-driven decision-making. We have seen, for example, that out-of-sample model performance generally deteriorates in our simulation experiments. In practice, this can be seen as a cost to model owners, that is the group of stakeholders using the model as decision-making tool. As we have set out in the introduction, these model owners will generally be unwilling to carry that cost, and hence can be expected to stop offering recourse to individuals altogether. This in turn is costly to those individuals that would otherwise derive utility from being offered recourse.</p>
<p>So, where does this leave us? We would argue that the expected external costs of individual recourse should be shared by all stakeholders. The most straight-forward way to achieve this is to introduce a penalty for external costs in the counterfactual search objective function, as we have set out in <a href="#eq-collective">Equation&nbsp;4</a>. This will on average lead to more costly counterfactual outcomes. But it may help to avoid extreme scenarios, in which minimal-cost recourse is reserved to a tiny minority of individuals. We have shown various types of shift-mitigating strategies that can be used to this end. Since all of these strategies can be seen simply as specific adaption of <a href="#eq-collective">Equation&nbsp;4</a>, they can be applied to any of the various counterfactual generators studied here.</p>
</section>
<section id="sec-limit" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> Limitations and Future Work</h1>
<p>While we believe that this work constitutes a valuable starting point for addressing existing issues in Algorithmic Recourse from a fresh perspective, we are aware of several of its limitations. In the following, we highlight some of these limitations and point to avenues for future research.</p>
<section id="private-vs.-external-costs" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="private-vs.-external-costs"><span class="header-section-number">9.1</span> Private vs.&nbsp;External Costs</h2>
<p>Perhaps the most crucial shortcoming of our work is that we merely point out that there exists a trade-off between private costs to the individual and external costs to the collective of stakeholders. We fall short of providing any definite answers as to how that trade-off may be resolved in practice. The mitigation strategies we have proposed here provide a good starting point, but they are ad-hoc, mechanical extensions of the existing AR framework. An interesting idea to explore in future work could be the potential for Pareto optimal Algorithmic Recourse, that is a collective recourse outcome in which no single individual can be made better off, without make at least one other individual worse off. This type of work would be interdisciplinary and could help to formalize some of the concepts presented in this work. For the time being, we suggest that the trade-off can be resolved on a case-by-case basis.</p>
</section>
<section id="experimental-setup" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="experimental-setup"><span class="header-section-number">9.2</span> Experimental Setup</h2>
<p>The experimental setup proposed here is designed to mimic a real-world recourse process in a simple fashion. In practice, models are in fact updated on a regular basis <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. We also find it plausible to assume that the implementation of recourse happens periodically for different individuals, rather that all at once at time <span class="math inline">\(t=0\)</span>. That being said, our experimental design is a vast over-simplification of potential real-world scenarios. In practice, any endogenous shifts that may occur can be expected to be entangled with exogenous shifts of the nature investigated in <span class="citation" data-cites="upadhyay2021towards"><a href="#ref-upadhyay2021towards" role="doc-biblioref">[14]</a></span>. We also make implicit assumptions about the utility functions of the involved agents that may well be too simple: individuals seeking recourse are assumed to always implement the proposed Counterfactual Explanations; conversely, the agent in charge of the model <span class="math inline">\(M\)</span> is assumed to always treat individuals that have implemented valid recourse as if they were truly now in the target class. Relating this back to the consumer credit example, we assume that the would-be borrowers are always willing and able to implement recourse and the bank is always willing to provide credit as would-be borrowers move across the decision boundary. In practice it is doubtful that agents behave according to such simple rules. Nonetheless, we think that our simple framework offers a starting point for future work on recourse dynamics (both endogenous and exogenous dynamics).</p>
</section>
<section id="sec-limit-data" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="sec-limit-data"><span class="header-section-number">9.3</span> Data</h2>
<p>Largely in line with the existing literature on Algorithmic Recourse, we have limited our analysis of real-world data to three commonly used benchmark datasets that involve binary prediction tasks. Future work may benefit from including novel datasets or extending the analysis to multi-class or regression problems, the latter arguably representing the most common objective in Finance and Economics. It is also worth mentioning that the use of real-world datasets considered in this work is constrained by the fact that at the time of writing <code>CounterfactualExplanations.jl</code> only supports continuous features, at least of some of the counterfactual generators considered here. The fact that we therefore had to discard discrete features led to relatively poor initial performance of our classifiers in some cases. While this is indeed a limitation we intend to address in future and derivative work, our findings with respect to endogenous macrodynamics do not hinge on strong classifier performance.</p>
</section>
<section id="classifiers" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="classifiers"><span class="header-section-number">9.4</span> Classifiers</h2>
<p>For reasons stated earlier we have limited our analysis to differentiable linear and non-linear classifiers, in particular logistic regression and deep neural networks. While these sorts of classifiers have also typically been analyzed in the existing literature on Counterfactual Explanations and Algorithmic Recourse, they represent only a subset of popular machine learning models employed in practice - both black-box and glass-box. Despite the success and popularity of deep learning in the context of high-dimensional data such as image, audio and video, empirical evidence suggests that other models such as boosted decision trees may have an edge when it comes to lower-dimensional tabular datasets, such as the ones considered here <span class="citation" data-cites="borisov2021deep"><a href="#ref-grinsztajn2022tree" role="doc-biblioref">[37]</a></span>.</p>
</section>
</section>
<section id="sec-conclusion" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> Concluding Remarks</h1>
<p>This work has revisited and extended some of the most general and defining concepts underlying the literature on Counterfactual Explanations and, in particular, Algorithmic Recourse. We demonstrate that long-held beliefs as to what defines optimality in AR, are too short-sighted to serve as a foundation for applications of recourse in practice. Specifically, we run multiple experiments that simulate the application of recourse in practice using various popular counterfactual generators and find that all of them induce substantial domain and model shifts. We argue that these shifts should be considered as an expected external cost of individual recourse and call for a paradigm shift from individual to collective recourse. By proposing an adapted counterfactual search objective that incorporates this cost, we make that paradigm shift explicit. We show that this modified objective lends itself to mitigation strategies that can be used to effectively decrease the magnitude of induced domain and model shifts. Through our work we hope to inspire future research on this important topic. To this end we have open-sourced all of our code along with a Julia package - <code>AlgorithmicRecourseDynamics.jl</code>. The package is built on top of <code>CounterfactualExplanations.jl</code> and inherits its extensibility <span class="citation" data-cites="altmeyer2022CounterfactualExplanations"><a href="#ref-altmeyer2022CounterfactualExplanations" role="doc-biblioref">[5]</a></span>. That is to say that future researchers should find it relatively easy to replicate, modify and extend the simulation experiments presented here and apply to their own custom counterfactual generators.</p>
</section>
<section id="references" class="level1 unnumbered">
<h1 class="unnumbered">References</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-o2016weapons" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">C. O’neil, <em>Weapons of math destruction: How big data increases inequality and threatens democracy</em>. Crown, 2016.</div>
</div>
<div id="ref-rudin2019stop" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">C. Rudin, <span>“Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead,”</span> <em>Nature Machine Intelligence</em>, vol. 1, no. 5, pp. 206–215, 2019.</div>
</div>
<div id="ref-pawelczyk2021carla" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">M. Pawelczyk, S. Bielawski, J. van den Heuvel, T. Richter, and G. Kasneci, <span>“Carla: A python library to benchmark algorithmic recourse and counterfactual explanation algorithms,”</span> <em>arXiv preprint arXiv:2108.00783</em>, 2021.</div>
</div>
<div id="ref-wachter2017counterfactual" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">S. Wachter, B. Mittelstadt, and C. Russell, <span>“Counterfactual explanations without opening the black box: Automated decisions and the GDPR,”</span> <em>Harv. JL &amp; Tech.</em>, vol. 31, p. 841, 2017.</div>
</div>
<div id="ref-altmeyer2022CounterfactualExplanations" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">P. Altmeyer, <em><span class="nocase">CounterfactualExplanations.jl - a Julia package for Counterfactual Explanations and Algorithmic Recourse</span></em>. 2022. Available: <a href="https://github.com/pat-alt/CounterfactualExplanations.jl">https://github.com/pat-alt/CounterfactualExplanations.jl</a></div>
</div>
<div id="ref-schut2021generating" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">L. Schut <em>et al.</em>, <span>“Generating interpretable counterfactual explanations by implicit minimisation of epistemic and aleatoric uncertainties,”</span> in <em>International conference on artificial intelligence and statistics</em>, 2021, pp. 1756–1764.</div>
</div>
<div id="ref-joshi2019towards" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">S. Joshi, O. Koyejo, W. Vijitbenjaronk, B. Kim, and J. Ghosh, <span>“Towards realistic individual recourse and actionable explanations in black-box decision making systems,”</span> <em>arXiv preprint arXiv:1907.09615</em>, 2019.</div>
</div>
<div id="ref-mothilal2020explaining" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">R. K. Mothilal, A. Sharma, and C. Tan, <span>“Explaining machine learning classifiers through diverse counterfactual explanations,”</span> in <em>Proceedings of the 2020 conference on fairness, accountability, and transparency</em>, 2020, pp. 607–617.</div>
</div>
<div id="ref-antoran2020getting" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">J. Antorán, U. Bhatt, T. Adel, A. Weller, and J. M. Hernández-Lobato, <span>“Getting a clue: A method for explaining uncertainty estimates,”</span> <em>arXiv preprint arXiv:2006.06848</em>, 2020.</div>
</div>
<div id="ref-karimi2020survey" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">A.-H. Karimi, G. Barthe, B. Schölkopf, and I. Valera, <span>“A survey of algorithmic recourse: Definitions, formulations, solutions, and prospects,”</span> <em>arXiv preprint arXiv:2010.04050</em>, 2020.</div>
</div>
<div id="ref-verma2020counterfactual" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">S. Verma, J. Dickerson, and K. Hines, <span>“Counterfactual explanations for machine learning: A review,”</span> <em>arXiv preprint arXiv:2010.10596</em>, 2020.</div>
</div>
<div id="ref-ustun2019actionable" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[12] </div><div class="csl-right-inline">B. Ustun, A. Spangher, and Y. Liu, <span>“Actionable recourse in linear classification,”</span> in <em>Proceedings of the conference on fairness, accountability, and transparency</em>, 2019, pp. 10–19.</div>
</div>
<div id="ref-karimi2021algorithmic" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[13] </div><div class="csl-right-inline">A.-H. Karimi, B. Schölkopf, and I. Valera, <span>“Algorithmic recourse: From counterfactual explanations to interventions,”</span> in <em>Proceedings of the 2021 ACM conference on fairness, accountability, and transparency</em>, 2021, pp. 353–362.</div>
</div>
<div id="ref-upadhyay2021towards" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[14] </div><div class="csl-right-inline">S. Upadhyay, S. Joshi, and H. Lakkaraju, <span>“Towards robust and reliable algorithmic recourse,”</span> <em>arXiv preprint arXiv:2102.13620</em>, 2021.</div>
</div>
<div id="ref-carrizosa2021generating" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[15] </div><div class="csl-right-inline">E. Carrizosa, J. Ramırez-Ayerbe, and D. Romero, <span>“Generating collective counterfactual explanations in score-based classification via mathematical optimization,”</span> 2021.</div>
</div>
<div id="ref-rabanser2019failing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[16] </div><div class="csl-right-inline">S. Rabanser, S. Günnemann, and Z. Lipton, <span>“Failing loudly: An empirical study of methods for detecting dataset shift,”</span> <em>Advances in Neural Information Processing Systems</em>, vol. 32, 2019.</div>
</div>
<div id="ref-chandola2009anomaly" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[17] </div><div class="csl-right-inline">V. Chandola, A. Banerjee, and V. Kumar, <span>“Anomaly detection: A survey,”</span> <em>ACM computing surveys (CSUR)</em>, vol. 41, no. 3, pp. 1–58, 2009.</div>
</div>
<div id="ref-widmer1996learning" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[18] </div><div class="csl-right-inline">G. Widmer and M. Kubat, <span>“Learning in the presence of concept drift and hidden contexts,”</span> <em>Machine learning</em>, vol. 23, no. 1, pp. 69–101, 1996.</div>
</div>
<div id="ref-gama2014survey" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[19] </div><div class="csl-right-inline">J. Gama, I. Žliobaitė, A. Bifet, M. Pechenizkiy, and A. Bouchachia, <span>“A survey on concept drift adaptation,”</span> <em>ACM computing surveys (CSUR)</em>, vol. 46, no. 4, pp. 1–37, 2014.</div>
</div>
<div id="ref-nelson2015evaluating" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[20] </div><div class="csl-right-inline">K. Nelson, G. Corbin, M. Anania, M. Kovacs, J. Tobias, and M. Blowers, <span>“Evaluating model drift in machine learning algorithms,”</span> in <em>2015 IEEE symposium on computational intelligence for security and defense applications (CISDA)</em>, 2015, pp. 1–8.</div>
</div>
<div id="ref-ackerman2021machine" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[21] </div><div class="csl-right-inline">S. Ackerman, P. Dube, E. Farchi, O. Raz, and M. Zalmanovici, <span>“Machine learning model drift detection via weak data slices,”</span> in <em>2021 IEEE/ACM third international workshop on deep learning for testing and testing for deep learning (DeepTest)</em>, 2021, pp. 1–8.</div>
</div>
<div id="ref-de2021framework" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[22] </div><div class="csl-right-inline">R. M. B. de Oliveira and D. Martens, <span>“A framework and benchmarking study for counterfactual generating methods on tabular data,”</span> <em>Applied Sciences</em>, vol. 11, no. 16, p. 7274, 2021.</div>
</div>
<div id="ref-dombrowski2021diffeomorphic" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[23] </div><div class="csl-right-inline">A.-K. Dombrowski, J. E. Gerken, and P. Kessel, <span>“Diffeomorphic explanations with normalizing flows,”</span> 2021.</div>
</div>
<div id="ref-pindyck2014microeconomics" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[24] </div><div class="csl-right-inline">R. S. Pindyck and D. L. Rubinfeld, <em>Microeconomics</em>. Pearson Education, 2014.</div>
</div>
<div id="ref-berlinet2011reproducing" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[25] </div><div class="csl-right-inline">A. Berlinet and C. Thomas-Agnan, <em>Reproducing kernel hilbert spaces in probability and statistics</em>. Springer Science &amp; Business Media, 2011.</div>
</div>
<div id="ref-gretton2012kernel" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[26] </div><div class="csl-right-inline">A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola, <span>“A kernel two-sample test,”</span> <em>The Journal of Machine Learning Research</em>, vol. 13, no. 1, pp. 723–773, 2012.</div>
</div>
<div id="ref-arcones1992bootstrap" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[27] </div><div class="csl-right-inline">M. A. Arcones and E. Gine, <span>“On the bootstrap of u and v statistics,”</span> <em>The Annals of Statistics</em>, pp. 655–674, 1992.</div>
</div>
<div id="ref-hanneke2007bound" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[28] </div><div class="csl-right-inline">S. Hanneke, <span>“A bound on the label complexity of agnostic active learning,”</span> in <em>Proceedings of the 24th international conference on machine learning</em>, 2007, pp. 353–360.</div>
</div>
<div id="ref-innes2018fashionable" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[29] </div><div class="csl-right-inline">M. Innes <em>et al.</em>, <span>“Fashionable modelling with flux,”</span> <em>arXiv preprint arXiv:1811.01457</em>, 2018.</div>
</div>
<div id="ref-lakshminarayanan2016simple" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[30] </div><div class="csl-right-inline">B. Lakshminarayanan, A. Pritzel, and C. Blundell, <span>“Simple and scalable predictive uncertainty estimation using deep ensembles,”</span> <em>arXiv preprint arXiv:1612.01474</em>, 2016.</div>
</div>
<div id="ref-gmsc_data" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[31] </div><div class="csl-right-inline">K. Competition, <span>“Give me some credit, improve on the state of the art in credit scoring by predicting the probability that somebody will experience financial distress in the next two years.”</span> <a href="https://www.kaggle.com/c/GiveMeSomeCredit">https://www.kaggle.com/c/GiveMeSomeCredit</a></div>
</div>
<div id="ref-yeh2009comparisons" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[32] </div><div class="csl-right-inline">I.-C. Yeh and C. Lien, <span>“The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients,”</span> <em>Expert systems with applications</em>, vol. 36, no. 2, pp. 2473–2480, 2009.</div>
</div>
<div id="ref-pedregosa2011scikit" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[33] </div><div class="csl-right-inline">F. Pedregosa <em>et al.</em>, <span>“Scikit-learn: Machine learning in python,”</span> <em>the Journal of machine Learning research</em>, vol. 12, pp. 2825–2830, 2011.</div>
</div>
<div id="ref-pace1997sparse" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[34] </div><div class="csl-right-inline">R. K. Pace and R. Barry, <span>“Sparse spatial autoregressions,”</span> <em>Statistics &amp; Probability Letters</em>, vol. 33, no. 3, pp. 291–297, 1997.</div>
</div>
<div id="ref-carlisle2019racist" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[35] </div><div class="csl-right-inline">C. M., <span>“Racist data destruction? - a boston housing dataset controversy,”</span> 2019, Available: <a href="https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8">https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8</a></div>
</div>
<div id="ref-borisov2021deep" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[36] </div><div class="csl-right-inline">V. Borisov, T. Leemann, K. Seßler, J. Haug, M. Pawelczyk, and G. Kasneci, <span>“Deep neural networks and tabular data: A survey,”</span> <em>arXiv preprint arXiv:2110.01889</em>, 2021.</div>
</div>
<div id="ref-grinsztajn2022tree" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[37] </div><div class="csl-right-inline">L. Grinsztajn, E. Oyallon, and G. Varoquaux, <span>“Why do tree-based models still outperform deep learning on tabular data?”</span> <em>arXiv preprint arXiv:2207.08815</em>, 2022.</div>
</div>
</div>
</section>





<div id="quarto-appendix" class="default"><section id="tables" class="level1 appendix" data-number="11"><h2 class="quarto-appendix-heading"><span class="header-section-number">11</span> Tables</h2><div class="quarto-appendix-contents">

<p>…</p>
</div></section><section id="figures" class="level1 appendix" data-number="12"><h2 class="quarto-appendix-heading"><span class="header-section-number">12</span> Figures</h2><div class="quarto-appendix-contents">

<p>…</p>
</div></section><section id="code" class="level1 appendix" data-number="13"><h2 class="quarto-appendix-heading"><span class="header-section-number">13</span> Code</h2><div class="quarto-appendix-contents">

<p>…</p>
</div></section><section class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1" role="doc-endnote"><p>Equivalently, others have referred to this quantity as <em>complexity</em> or simply <em>distance</em><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>The package is available from …<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>In fact, there are a number of other recently proposed approaches to counterfactual search that also broadly fall in this same category. They largely differ with respect to the chosen generative model: for example, the generator proposed by <span class="citation" data-cites="dombrowski2021diffeomorphic"><a href="#ref-dombrowski2021diffeomorphic" role="doc-biblioref">[23]</a></span> relies on normalizing flows.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>DiCE recognizes that different individuals may have different objective functions, but it does not address the interdependencies between different individuals.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>As mentioned in the previous section, we end up providing recourse to a total of <span class="math inline">\(\approx50\%\)</span> by the end of round <span class="math inline">\(T=50\)</span>.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>As we mentioned earlier, the diversity constraint used by DiCE is only effective for when at least two counterfactuals are being generated. We have therefore decided to always generate 5 counterfactuals for each generator and randomly pick one of them.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>These have been ommitted from the analysis. See <a href="#sec-limit-data">Section&nbsp;9.3</a> for details.<a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Note that despite the naming convention our goal here is not to provide yet another counterfactual generator, but merely investigate the most simple penalty we can think of with respect to its effectiveness.<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>In order for the Graviational generator and ClapROAR to work as expected, one needs to ensure that counterfactual search continues, independent of the threshold probability <span class="math inline">\(\gamma\)</span>.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div quarto-reuse="quarto-reuse" class="quarto-appendix-contents"><a rel="license" href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</a></div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>
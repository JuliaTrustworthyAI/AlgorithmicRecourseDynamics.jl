# Packages
using LinearAlgebra

# Sigmoid function:
function ğ›”(a)
    trunc = 8.0 # truncation to avoid numerical over/underflow
    a = clamp.(a,-trunc,trunc)
    p = exp.(a)
    p = p ./ (1 .+ p)
    return p
end

# Negative log likelihood
function ğ“(w,w_0,H_0,X,y)
    N = length(y)
    D = size(X)[2]
    Î¼ = ğ›”(X*w)
    Î”w = w-w_0
    return - âˆ‘( y[n] * log(Î¼[n]) + (1-y[n]) * log(1-Î¼[n]) for n=1:N) + 1/2 * Î”w'H_0*Î”w
end

# Negative log likelihood (unconstrained)
function ğ“_(w,w_0,H_0,X,y)
    N = length(y)
    D = size(X)[2]
    #a = clamp.(X*w, -8.0, 8.0)
    a = X*w
    Î”w = w-w_0
    return a'y .- log.(1 .+ exp.(a')) * ones(N) .+ 1/2 * Î”w'H_0*Î”w
end

# Gradient:
function âˆ‡ğ“(w,w_0,H_0,X,y)
    N = length(y)
    Î¼ = ğ›”(X*w)
    Î”w = w-w_0
    g = âˆ‘((Î¼[n]-y[n]) * X[n,:] for n=1:N)
    return g + H_0*Î”w
end

# Hessian:
function âˆ‡âˆ‡ğ“(w,w_0,H_0,X,y)
    N = length(y)
    Î¼ = ğ›”(X*w)
    H = âˆ‘(Î¼[n] * (1-Î¼[n]) * X[n,:] * X[n,:]' for n=1:N)
    return H + H_0
end

# Main function:
struct BayesLogreg
    Î¼::Vector{Float64}
    Î£::Matrix{Float64}
end
function bayes_logreg(X,y,w_0,H_0,ğ“,âˆ‡ğ“,âˆ‡âˆ‡ğ“,optim_options...)
    # Model:
    w_map, H_map = newton(ğ“, w_0, âˆ‡ğ“, âˆ‡âˆ‡ğ“, (w_0=w_0, H_0=H_0, X=X, y=y), optim_options...) # fit the model (find mode of posterior distribution)
    Î£_map = inv(H_map) # inverse Hessian at the mode
    Î£_map = Symmetric(Î£_map) # to ensure matrix is Hermitian (i.e. avoid rounding issues)
    # Output:
    mod = BayesLogreg(w_map, Î£_map)
    return mod
end

# Methods:
Î¼(mod::BayesLogreg) = mod.Î¼
Î£(mod::BayesLogreg) = mod.Î£
# Predict from classifier:
function predict(mod::BayesLogreg, X, proba=true)
    Î¼ = mod.Î¼ # MAP mean vector
    y_hat = ğ›”(X*w)
    if (proba)
        y_hat = round.(y_hat)
    end
    return(y_hat)
end
# Sampling from posterior distribution:
using Distributions
function sample_posterior(mod::BayesLogreg, n)
    rand(MvNormal(mod.Î¼, mod.Î£),n)
end
# Posterior predictions:
function posterior_predictive(mod::BayesLogreg, X)
    Î¼ = mod.Î¼ # MAP mean vector
    Î£ = mod.Î£ # MAP covariance matrix
    if !isa(X, Matrix)
        X = reshape(X, 1, length(X))
    end
    # Inner product:
    z = X*Î¼
    # Probit approximation
    v = [X[n,:]'Î£*X[n,:] for n=1:size(X)[1]]
    Îº = 1 ./ sqrt.(1 .+ Ï€/8 .* v) 
    z = Îº .* z
    # Truncation to avoid numerical over/underflow:
    trunc = 8.0 
    z = clamp.(z,-trunc,trunc)
    p = exp.(z)
    p = p ./ (1 .+ p)
    return p
end

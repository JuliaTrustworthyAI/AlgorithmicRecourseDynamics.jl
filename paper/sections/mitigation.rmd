# Mitigation Strategies and Experiments {#mitigate}

Having established in the previous section that endogenous macrodynamics in AR are substantial enough to warrant our attention, in this section we ask ourselves:

::: {.proposition #mitigate name="Mitigation Strategies"}
What are potential mitigation strategies with respect to endogenous macrodynamics in AR?
:::

We proposed and test a number of simple mitigation strategies. All of them essentially boil down to one simple principle: to avoid substantial domain and model shifts, the generated counterfactuals should comply as much as possible with the true data generating process. This principle is really at the core of Latent Space (LS) generators, and hence it is not surprising that we have found these types of generators to perform comparably well in the previous section. But as we have mentioned earlier, generators that rely on separate generative models carry an additional computational burden and, perhaps more importantly, their performance hinges on the performance of said generative models. Fortunately, it turns out that we can use a number of other, much simpler strategies.

## More Conservative Decision Thresholds

The most obvious and trivial mitigation strategy is to simply choose a higher decision threshold $\gamma$. This threshold determines when a counterfactual should be considered as valid. Under $\gamma=0.5$, counterfactuals will end up near the decision boundary by construction. Since this is the region of maximal aleatoric uncertainty, the classifier is bound to be thrown off. By setting a more conservative threshold, we can avoid this issue to some extent. A drawback of this approach is that a classifier with high decisiveness may classify samples with high confidence even far away from the training data. 

## Classifier Preserving ROAR (ClaPROAR)

Another strategy draws inspiration from ROAR @upadhyay2021robust: to preserve the classifier, we propose to explicitly penalize the loss it incurs when evaluated on the counterfactual $x^\prime$ at given parameter values. Recall that $\text{extcost}(\cdot)$ denotes what we had defined as the external cost in Equation \@ref(eq:collective). Formally, we let

\begin{equation}
\begin{aligned}
\text{extcost}(f(\mathbf{s}^\prime)) = l(M(f(\mathbf{s}^\prime)),y^\prime) (\#eq:clap)
\end{aligned}
\end{equation} 

for each counterfactual $k$ where $l$ denotes the loss function used to train $M$. This approach, which we refer to as **ClaPROAR**, is based on the intuition that (endogenous) model shifts will be triggered by counterfactuals that increase classifier loss. It is closely linked to the idea of choosing a higher decision threshold, but likely better at avoiding the potential pitfalls associated with highly decisive classifiers. It also makes the private vs. external cost trade-off more explicit and hence manageable.

## Gravitational Counterfactual Explanations 

Yet another strategy extends Wachter as follows: instead of only penalizing the distance of the individuals' counterfactual to its factual, we propose penalizing its distance to some sensible point in the target domain, for example the subsample average $\bar{x}^*=\text{mean}(x)$, $x \in \mathcal{D}_1$:

\begin{equation}
\begin{aligned}
\text{extcost}(f(\mathbf{s}^\prime)) = \text{dist}(f(\mathbf{s}^\prime),\bar{x}^*)  (\#eq:grav)
\end{aligned}
\end{equation}

Once again we can putting this in the context of Equation \@ref(eq:collective): the former penalty can be thought of here as the private cost incurred by the individual, while the latter reflects the external cost incurred by other individuals. Higher choices of $\lambda_2$ relative to $\lambda_1$ will lead counterfactuals to gravitate towards the specified point $\bar{x}$ in the target domain. In the remainder of this paper, we will therefore refer to this approach as **Gravitational** generator, when we investigate its usefulness for mitigating endogenous macrodynamics^[Note that despite the naming conventions, our goal here is not to provide yet more counterfactual generators. Rather than looking at them as isolated entities, we believe and demonstrate that different approaches can be effectively combined.]. 

Figure \@ref(fig:mitigation) shows an illustrative example that demonstrates the differences in counterfactual outcomes when using the various mitigation strategies compared to the baseline approach, that is, Wachter with $\gamma=0.5$: choosing a higher decision threshold pushes the counterfactual a little further into the target domain; this effect is even stronger for ClaPROAR; finally, using the Gravitational generator the counterfactual ends up all the way inside the target domain in the neighbourhood of $\bar{x}$^[In order for the Gravitational generator and ClaPROAR to work as expected, one needs to ensure that counterfactual search continues, independent of the threshold probability $\gamma$.]. Linking these ideas back to Example \@ref(exm:student), the mitigation strategies help ensure that the recommended recourse actions are substantial enough to truly lead to an increase in the probability that the admitted student eventually graduates.

```{julia, eval=FALSE, echo=FALSE}
using Random
Random.seed!(2022)

# Data:
using MLJ
N = 1000
X, ys = make_blobs(N, 2; centers=2, as_table=false, center_box=(-5 => 5), cluster_std=0.5)
ys .= ys.==2
X = X'
xs = Flux.unstack(X,2)
data = zip(xs,ys)
counterfactual_data = CounterfactualData(X,ys')

# Models:
using AlgorithmicRecourseDynamics
M = AlgorithmicRecourseDynamics.Models.FluxModel(counterfactual_data)
M = AlgorithmicRecourseDynamics.Models.train(M, counterfactual_data)

# Generators:
generators = Dict(
    "Generic (γ=0.5)" => GenericGenerator(decision_threshold=0.5),
    "Generic (γ=0.9)" => GenericGenerator(decision_threshold=0.9),
    "Gravitational" => GravitationalGenerator(),
    "ClaPROAR" => ClaPROARGenerator()
)

# Counterfactuals
x = select_factual(counterfactual_data, rand(1:size(X)[2])) 
y = round(probs(M, x)[1])
target = ifelse(y==1.0,0.0,1.0) # opposite label as target
T = 50
counterfactuals = Dict([name => generate_counterfactual(x, target, counterfactual_data, M, gen; T=T, latent_space=false) for (name, gen) in generators])

# Plots:
plts = []
for (name,ce) ∈ counterfactuals
    plt = plot(ce; title=name, colorbar=false, ticks = false, legend=false)
    plts = vcat(plts..., plt)
end
plt = plot(plts..., size=(750,200), layout=(1,4))
savefi\text{extcost}(plt, "dev/paper/www/mitigation.png")
```


```{r mitigation, fig.cap="Illustrative example demonstrating the properties of the various mitigation strategies. Samples from the negative class ($y=0$) are marked in blue while samples of the positive class ($y=1$) are marked in orange."}
knitr::include_graphics("www/mitigation.png")
```

Our findings indicate that all three mitigation strategies are at least at par with LS generators with respect to their effectiveness at mitigating domain and model shifts. Figure \@ref(fig:mitigate-results) presents a subset of the evaluation metrics for our synthetic data with overlapping classes. The top row in Figure \@ref(fig:mitigate-results) indicates that while domain shifts are of roughly the same magnitude for both Wachter and LS generators, our proposed strategies effectively mitigate these shifts. ClaPROAR appears to be particularly effective, which is positively surprising, since it is designed to explicitly address model shifts, not domain shifts. As evident from the middle row in Figure \@ref(fig:mitigate-results) model shifts can also be reduced: for the deep ensemble LS search yields results that are at par with the mitigation strategies, while for both the simple MLP and logistic regression our simple strategies are actually more effective. The same overall pattern can be observed for out-of-sample model performance. With respect to the other synthetic datasets, for the Moons dataset, the emerging patterns are largely the same, but the estimated model shifts are insignificant as noted earlier; the same holds for the Circles dataset, but there is no significant reduction in model performance for our neural networks; in the case of linearly separable data we find the Gravitational generator to be most effective at mitigating shifts. 

```{r mitigate-results, fig.cap="The differences in counterfactual outcomes when using the various mitigation strategies compared to the baseline approach, that is Wachter with $\\gamma=0.5$. Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a mesh grid of points. Error bars indicate the standard deviation across folds."}
knitr::include_graphics("www/mitigation_synthetic_results.png")
```

An interesting finding is also that the proposed strategies have a complementary effect when used in combination with LS generators. In experiments we conducted on the synthetic data, the benefits of LS generators were exacerbated further when using a more conservative threshold or combining it with the penalties underlying Gravitational and ClaPROAR. In Figure \@ref(fig:mitigate-latent-results) the conventional LS generator with $\gamma=0.5$ serves as our baseline. Evidently, being more conservative or using one of our proposed penalties decreases the estimated domain and model shifts.

```{r mitigate-latent-results, fig.cap="Combinining various mitigation strategies with LS search. Results for synthetic data with overlapping classes. The shown model MMD (PP MMD) was computed over a mesh grid of points. Error bars indicate the standard deviation across folds."}
knitr::include_graphics("www/mitigation_synthetic_latent_results.png")
```

Finally, Figure \@ref(fig:mitigate-real-world-results) shows the results for our real-world data. We note that for both California Housing and Credit Default data our proposed strategies do have an attenuating effect on both model shifts and performance deterioration, even though the estimated effects are somewhat less striking than for the synthetic data in Figure \@ref(fig:mitigate-results)^[Estimated domain shifts (not shown) were largely insubstantial, as in Figure \@ref(fig:real) in the previous section.]. Still, both ClaPROAR and Gravitational reduce the negative impact on out-of-sample model performance by around 25 percent from roughly 20 percentage points for the baseline approach to just 15 percentage points. For the GMSC dataset we observe no notable differences.

```{r mitigate-real-world-results, fig.cap="The differences in counterfactual outcomes when using the various mitigation strategies compared to the baseline approach, that is Wachter with $\\gamma=0.5$. Results for deep ensemble using real-world datasets. The shown model MMD (PP MMD) was computed over actual samples, rather than a mesh grid. Error bars indicate the standard deviation across folds."}
knitr::include_graphics("www/mitigation_real_world_results.png")
```


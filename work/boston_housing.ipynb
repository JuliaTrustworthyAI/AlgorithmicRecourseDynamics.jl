{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: replacing module Models.\n",
      "WARNING: replacing module Experiments.\n"
     ]
    }
   ],
   "source": [
    "include(\"../src/load.jl\")\n",
    "using AlgorithmicRecourse, MLDatasets, Flux\n",
    "using Plots, PlotThemes\n",
    "theme(:juno)\n",
    "using Logging\n",
    "disable_logging(Logging.Info)\n",
    "output_folder = \"output/boston_housing\"\n",
    "www_folder = \"www/boston_housing\"\n",
    "using DataFrames, CSV\n",
    "using BSON: @save, @load\n",
    "using Base.Filesystem: joinpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets, Statistics\n",
    "X = BostonHousing.features()\n",
    "y = BostonHousing.targets()\n",
    "y = Float64.(y .>= median(y)); # binary target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start off we will just train a single neural network for the binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare data and model:\n",
    "using Random\n",
    "Random.seed!(1234)\n",
    "using StatsBase\n",
    "dt = fit(ZScoreTransform, X, dims=2)\n",
    "StatsBase.transform!(dt, X)\n",
    "xs = Flux.unstack(X,2)\n",
    "data = zip(xs,y)\n",
    "nn = Models.build_model(input_dim=size(X)[1], n_hidden=100)\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(nn(x), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model achieves decent training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = false\n",
    "if run\n",
    "  # Train model:\n",
    "  using Flux.Optimise: update!, ADAM\n",
    "  using Statistics, StatsBase\n",
    "  opt = ADAM()\n",
    "  epochs = 100\n",
    "  avg_loss(data) = mean(map(d -> loss(d[1],d[2]), data))\n",
    "  accuracy(data) = sum(map(d ->round.(Flux.œÉ.(nn(d[1]))) .== d[2], data))[1]/length(data)\n",
    "\n",
    "  using Plots\n",
    "  anim = Animation()\n",
    "  avg_l = [avg_loss(data)]\n",
    "  p1 = scatter( ylim=(0,avg_l[1]), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Average loss\")\n",
    "  acc = [accuracy(data)]\n",
    "  p2 = scatter( ylim=(0.5,1), xlim=(0,epochs), legend=false, xlab=\"Epoch\", title=\"Accuracy\")\n",
    "  \n",
    "  œÑ = 1.0\n",
    "  stopping_criterium_reached = accuracy(data) >= œÑ\n",
    "  epoch = 1\n",
    "\n",
    "  while epoch <= epochs && !stopping_criterium_reached\n",
    "    for d in data\n",
    "      gs = gradient(params(nn)) do\n",
    "        l = loss(d...)\n",
    "      end\n",
    "      update!(opt, params(nn), gs)\n",
    "    end\n",
    "    avg_l = vcat(avg_l,avg_loss(data))\n",
    "    plot!(p1, [0:epoch], avg_l, color=1)\n",
    "    scatter!(p1, [0:epoch], avg_l, color=1)\n",
    "    acc = vcat(acc,accuracy(data))\n",
    "    plot!(p2, [0:epoch], acc, color=1)\n",
    "    scatter!(p2, [0:epoch], acc, color=1)\n",
    "    plt=plot(p1,p2, size=(600,300))\n",
    "    frame(anim, plt)\n",
    "\n",
    "    # Check if desired accuracy reached:\n",
    "    stopping_criterium_reached = accuracy(data) >= œÑ\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "  end\n",
    "\n",
    "  gif(anim, joinpath(www_folder, \"single_nn.gif\"), fps=10)\n",
    "\n",
    "  using BSON: @save\n",
    "  @save joinpath(output_folder, \"nn.bson\") nn\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing/single_nn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build and train a deep ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM()\n",
    "loss_type = :logitbinarycrossentropy\n",
    "run = false\n",
    "if run\n",
    "    K = 50\n",
    "    ùìú = Models.build_ensemble(K,kw=(input_dim=size(X)[1], n_hidden=100));\n",
    "    ùìú, anim = Models.forward(ùìú, data, opt, n_epochs=30, plot_every=10, loss_type=loss_type); # fit the ensemble\n",
    "    Models.save_ensemble(ùìú, root=joinpath(output_folder, \"ensemble\")) # save to disk\n",
    "    gif(anim, joinpath(www_folder, \"ensemble_loss.gif\"), fps=25);\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](www/boston_housing/ensemble_loss.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BSON: @load\n",
    "@load joinpath(output_folder, \"nn.bson\") nn\n",
    "ùë¥‚Çô‚Çô = Models.FittedNeuralNet(nn, opt, loss);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare ensemble for use with AlgorithmicRecourse.jl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùìú = Models.load_ensemble(root=joinpath(output_folder, \"ensemble\"))\n",
    "ùë¥ = Models.FittedEnsemble(ùìú, opt, loss_type);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare grid of variables for experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables:\n",
    "Œº = [0.01,0.1,0.25]\n",
    "Œ≥ = [0.50,0.75,0.9]\n",
    "grid_ = Experiments.GridVariables(Œº, Œ≥)\n",
    "n_rounds = 10\n",
    "target=1.0\n",
    "T = 1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic generator for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment:\n",
    "experiment = Experiments.Experiment(X,y,ùë¥‚Çô‚Çô,target,grid_,n_rounds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: objects of type Nothing are not callable",
     "output_type": "error",
     "traceback": [
      "MethodError: objects of type Nothing are not callable\n",
      "\n",
      "Stacktrace:\n",
      "  [1] logits(ùë¥::Main.Models.FittedNeuralNet, X::Vector{Float64})\n",
      "    @ Main.Models ~/OneDrive - Delft University of Technology/git/recourse/src/models/deep_ensemble.jl:95\n",
      "  [2] probs(ùë¥::Main.Models.FittedNeuralNet, X::Vector{Float64})\n",
      "    @ Main.Models ~/OneDrive - Delft University of Technology/git/recourse/src/models/deep_ensemble.jl:102\n",
      "  [3] generate_recourse(generator::GenericGenerator, xÃÖ::Vector{Float64}, ùë¥::Main.Models.FittedNeuralNet, target::Float64, Œ≥::Float64; T::Int64)\n",
      "    @ AlgorithmicRecourse ~/.julia/packages/AlgorithmicRecourse/5IWwN/src/core.jl:48\n",
      "  [4] run_experiment(experiment::Main.Experiments.Experiment, generator::GenericGenerator, n_folds::Int64; seed::Nothing, T::Int64, œÑ::Float64, store_path::Bool)\n",
      "    @ Main.Experiments ~/OneDrive - Delft University of Technology/git/recourse/src/experiments/functions.jl:88\n",
      "  [5] top-level scope\n",
      "    @ ~/OneDrive - Delft University of Technology/git/recourse/work/boston_housing.ipynb:7\n",
      "  [6] eval\n",
      "    @ ./boot.jl:360 [inlined]\n",
      "  [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1116\n",
      "  [8] #invokelatest#2\n",
      "    @ ./essentials.jl:708 [inlined]\n",
      "  [9] invokelatest\n",
      "    @ ./essentials.jl:706 [inlined]\n",
      " [10] (::VSCodeServer.var\"#146#147\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/packages/VSCodeServer/src/serve_notebook.jl:18\n",
      " [11] withpath(f::VSCodeServer.var\"#146#147\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/packages/VSCodeServer/src/repl.jl:185\n",
      " [12] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/packages/VSCodeServer/src/serve_notebook.jl:14\n",
      " [13] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [14] serve_notebook(pipename::String; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/packages/VSCodeServer/src/serve_notebook.jl:94\n",
      " [15] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.5.10/scripts/notebook/notebook.jl:12\n",
      " [16] include(mod::Module, _path::String)\n",
      "    @ Base ./Base.jl:384\n",
      " [17] exec_options(opts::Base.JLOptions)\n",
      "    @ Base ./client.jl:285\n",
      " [18] _start()\n",
      "    @ Base ./client.jl:485"
     ]
    }
   ],
   "source": [
    "run = true\n",
    "if run  \n",
    "    Œõ = [0.0, 0.1, 0.25, 0.5] \n",
    "    outcome = DataFrame()\n",
    "    for Œª in Œõ\n",
    "        generator = GenericGenerator(Œª,0.1,1e-5,:logitbinarycrossentropy,nothing)\n",
    "        outcome_Œª, path = Experiments.run_experiment(experiment, generator, 5, T=T)\n",
    "        outcome_Œª = DataFrame(outcome_Œª)\n",
    "        insertcols!(outcome_Œª, :Œª => Œª)\n",
    "        outcome = vcat(outcome, outcome_Œª)\n",
    "    end\n",
    "    CSV.write(joinpath(output_folder, \"mlp_generic.csv\"), outcome)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = CSV.read(joinpath(output_folder, \"mlp_generic.csv\"), DataFrame)\n",
    "\n",
    "function prepare_results(outcome; id_vars=[:t, :Œº, :Œ≥])\n",
    "    validity = groupby(outcome, id_vars) |>\n",
    "        gdf -> combine(gdf, :pct_valid .=> [mean, std] .=> [:mean, :std])\n",
    "    validity[!,:ymin] = validity[!,:mean] - validity[!,:std]\n",
    "    validity[!,:ymax] = validity[!,:mean] + validity[!,:std]\n",
    "\n",
    "    cost = groupby(outcome, id_vars) |>\n",
    "        gdf -> combine(gdf, :avg_cost .=> [mean, std] .=> [:mean, :std])\n",
    "    cost[!,:ymin] = cost[!,:mean] - cost[!,:std]\n",
    "    cost[!,:ymax] = cost[!,:mean] + cost[!,:std];\n",
    "\n",
    "    return validity, cost\n",
    "end\n",
    "\n",
    "validity‚ÇÄ, cost‚ÇÄ = prepare_results(outcome[outcome.Œª .== 0.0,:]);\n",
    "insertcols!(validity‚ÇÄ, :generator => \"Generic\")\n",
    "insertcols!(cost‚ÇÄ, :generator => \"Generic\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy generator for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment:\n",
    "experiment = Experiments.Experiment(X,y,ùë¥,target,grid_,n_rounds);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = true\n",
    "if run\n",
    "    n = round(T/size(X)[1])\n",
    "    Œ¥ = 0.1\n",
    "    generator = GreedyGenerator(Œ¥,n,:logitbinarycrossentropy,nothing)\n",
    "    outcome, path = Experiments.run_experiment(experiment, generator, 5, T=T)\n",
    "    CSV.write(joinpath(output_folder, \"ensemble_greedy.csv\"), DataFrame(outcome))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = CSV.read(joinpath(output_folder, \"ensemble_greedy.csv\"), DataFrame)\n",
    "\n",
    "validity‚ÇÅ, cost‚ÇÅ = prepare_results(outcome,id_vars=[:t, :Œº, :Œ≥])\n",
    "insertcols!(validity‚ÇÅ, :generator => \"Ensemble (greedy)\")\n",
    "insertcols!(cost‚ÇÅ, :generator => \"Ensemble (greedy)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic generator for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = true\n",
    "if run  \n",
    "    generator = GenericGenerator(0.0,0.1,1e-5,:logitbinarycrossentropy,nothing)\n",
    "    outcome, path = Experiments.run_experiment(experiment, generator, 5, T=T)\n",
    "    CSV.write(joinpath(output_folder, \"ensemble_generic.csv\"), DataFrame(outcome))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = CSV.read(joinpath(output_folder, \"ensemble_generic.csv\"), DataFrame)\n",
    "\n",
    "validity‚ÇÇ, cost‚ÇÇ = prepare_results(outcome,id_vars=[:t, :Œº, :Œ≥])\n",
    "insertcols!(validity‚ÇÇ, :generator => \"Ensemble (generic)\")\n",
    "insertcols!(cost‚ÇÇ, :generator => \"Ensemble (generic)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity = vcat(validity‚ÇÄ,validity‚ÇÅ,validity‚ÇÇ)\n",
    "cost = vcat(cost‚ÇÄ,cost‚ÇÅ,cost‚ÇÇ);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gadfly\n",
    "function plot_results(results; title=\"\")\n",
    "    set_default_plot_size(700px, 600px)\n",
    "    Gadfly.plot(\n",
    "        results, \n",
    "        xgroup=\"Œº\", ygroup=\"Œ≥\", x=\"t\", y=\"mean\", ymin=:ymin, ymax=:ymax, color=:generator,\n",
    "        Geom.subplot_grid(Geom.point, Geom.errorbar),\n",
    "        Guide.title(title)\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(cost, title=\"Cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(validity, title=\"Validity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.4",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
